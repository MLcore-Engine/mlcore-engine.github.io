<!DOCTYPE html>
<html lang="zh-cn">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<title>模型量化基础代码版 - 高新 | AI平台开发工程师</title>
<meta name="description" content="AI平台开发工程师，专注于AI平台工程和Kubernetes云原生技术。拥有AI平台开发、GPU资源优化和AI服务部署经验">
<meta name="generator" content="Hugo 0.145.0">
<link href="http://localhost:1313//index.xml" rel="alternate" type="application/rss+xml">
<link rel="canonical" href="http://localhost:1313/transformer/quantization/">
<link rel="stylesheet" href="http://localhost:1313/css/theme.min.css">
<link rel="stylesheet" href="http://localhost:1313/css/chroma.min.css">
<script defer src="http://localhost:1313//js/fontawesome6/all.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js" integrity="sha256-H3cjtrm/ztDeuhCN9I4yh4iN2Ybx/y1RM7rMmAesA0k=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js" integrity="sha256-4XodgW4TwIJuDtf+v6vDJ39FVxI0veC/kSCCmnFp7ck=" crossorigin="anonymous"></script>
<script src="http://localhost:1313/js/bundle.js"></script><style>
 
@media screen and (min-width: 480px) {
  .sidebar {
    flex: 0 0 20% !important;
    max-width: 20% !important;
  }
  
  main {
    flex: 0 0 80% !important;
    max-width: 80% !important;
  }
}

 
body {
  background-color: #f8f5e6 !important;  
  font-family: 'KaiTi', 'STKaiti', '楷体', '楷体_GB2312', 'SimKai', '华文楷体', Kai, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif !important;  
  font-size: 20px !important;  
  line-height: 1.8 !important;  
}

 
.container, .content-container, main {
  background-color: #f8f5e6 !important;
}

 
.sidebar {
  background-color: inherit;
  font-size: 16px !important;  
}

 
h1, h2, h3, h4, h5, h6 {
  font-family: 'KaiTi', 'STKaiti', '楷体', '楷体_GB2312', 'SimKai', '华文楷体', Kai, 'Noto Serif', Georgia, serif !important;
  font-weight: 600 !important;
  line-height: 1.5 !important;
}

 
h1 {
  font-size: 2.4em !important;
}

h2 {
  font-size: 2em !important;
}

h3 {
  font-size: 1.7em !important;
}

h4 {
  font-size: 1.5em !important;
}

h5 {
  font-size: 1.3em !important;
}

h6 {
  font-size: 1.2em !important;
}

 
p {
  font-size: 20px !important;
  margin-bottom: 1.2em !important;
}

 
li {
  font-size: 20px !important;
  margin-bottom: 0.5em !important;
}

 
article, .content, .post-content, main p, main li, main td, main th, blockquote, .markdown {
  font-size: 20px !important;
}

 
pre, code {
  font-family: 'JetBrains Mono', Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace !important;
  font-size: 1.1em !important;  
}

 
a {
  color: #0066cc !important;
  text-decoration: none !important;
}

a:hover {
  text-decoration: underline !important;
}

 
table {
  font-size: 20px !important;
}
</style> <meta property="og:url" content="http://localhost:1313/transformer/quantization/">
  <meta property="og:site_name" content="高新 | AI平台开发工程师">
  <meta property="og:title" content="模型量化基础代码版">
  <meta property="og:description" content="深度学习模型量化完整教程 目录 量化基础理论 量化的数学原理 量化方法详解 PyTorch量化实战 量化感知训练(QAT) 高级量化技术 量化调试与优化 实际案例分析 常见问题与解决方案 1. 量化基础理论 1.1 什么是模型量化？ 模型量化是将神经网络中的浮点数参数和计算转换为低精度表示的技术。这个过程类似于音频的数字化采样：将连续的模拟信号转换为离散的数字信号。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="transformer">
    <meta property="article:published_time" content="2025-05-27T15:58:39+08:00">
    <meta property="article:modified_time" content="2025-05-31T22:50:26+08:00">
    <meta property="og:image" content="http://localhost:1313/home/me.png">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:1313/home/me.png">
  <meta name="twitter:title" content="模型量化基础代码版">
  <meta name="twitter:description" content="深度学习模型量化完整教程 目录 量化基础理论 量化的数学原理 量化方法详解 PyTorch量化实战 量化感知训练(QAT) 高级量化技术 量化调试与优化 实际案例分析 常见问题与解决方案 1. 量化基础理论 1.1 什么是模型量化？ 模型量化是将神经网络中的浮点数参数和计算转换为低精度表示的技术。这个过程类似于音频的数字化采样：将连续的模拟信号转换为离散的数字信号。">

  <meta itemprop="name" content="模型量化基础代码版">
  <meta itemprop="description" content="深度学习模型量化完整教程 目录 量化基础理论 量化的数学原理 量化方法详解 PyTorch量化实战 量化感知训练(QAT) 高级量化技术 量化调试与优化 实际案例分析 常见问题与解决方案 1. 量化基础理论 1.1 什么是模型量化？ 模型量化是将神经网络中的浮点数参数和计算转换为低精度表示的技术。这个过程类似于音频的数字化采样：将连续的模拟信号转换为离散的数字信号。">
  <meta itemprop="datePublished" content="2025-05-27T15:58:39+08:00">
  <meta itemprop="dateModified" content="2025-05-31T22:50:26+08:00">
  <meta itemprop="wordCount" content="9717">
  <meta itemprop="image" content="http://localhost:1313/home/me.png">
<link rel="apple-touch-icon" sizes="180x180" href="/favicon/favicon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
<link rel="manifest" href="/favicon/site.webmanifest">
<link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="/favicon.ico">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/favicon/browserconfig.xml">
<meta name="theme-color" content="#ffffff"> 


<meta name="description" content="深度学习模型量化完整教程 目录 量化基础理论 量化的数学原理 量化方法详解 PyTorch量化实战 量化感知训练(QAT) 高级量化技术 量化调试与优化 实际案例分析 常见问题与解决方案 1. 量化基础理论 1.1 什么是模型量化？ 模型量化是将神经网络中的浮点数参数和计算转换为低精度表示的技术。这个过程类似于音频的数字化采样：将连续的模拟信号转换为离散的数字信号。
">
<meta name="keywords" content="AI, 机器学习, golang, kubernetes, 技术博客">
<meta name="author" content="高新">


<meta property="og:type" content="article">
<meta property="og:url" content="http://localhost:1313/transformer/quantization/">
<meta property="og:title" content="模型量化基础代码版 | 高新 | AI平台开发工程师">
<meta property="og:description" content="深度学习模型量化完整教程 目录 量化基础理论 量化的数学原理 量化方法详解 PyTorch量化实战 量化感知训练(QAT) 高级量化技术 量化调试与优化 实际案例分析 常见问题与解决方案 1. 量化基础理论 1.1 什么是模型量化？ 模型量化是将神经网络中的浮点数参数和计算转换为低精度表示的技术。这个过程类似于音频的数字化采样：将连续的模拟信号转换为离散的数字信号。
">
<meta property="og:image" content="http://localhost:1313/home/me.png">


<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:url" content="http://localhost:1313/transformer/quantization/">
<meta name="twitter:title" content="模型量化基础代码版 | 高新 | AI平台开发工程师">
<meta name="twitter:description" content="深度学习模型量化完整教程 目录 量化基础理论 量化的数学原理 量化方法详解 PyTorch量化实战 量化感知训练(QAT) 高级量化技术 量化调试与优化 实际案例分析 常见问题与解决方案 1. 量化基础理论 1.1 什么是模型量化？ 模型量化是将神经网络中的浮点数参数和计算转换为低精度表示的技术。这个过程类似于音频的数字化采样：将连续的模拟信号转换为离散的数字信号。
">
<meta name="twitter:image" content="http://localhost:1313/home/me.png">


<link rel="canonical" href="http://localhost:1313/transformer/quantization/">


<link rel="stylesheet" href="/css/math.css">


<script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script id="MathJax-script" async src="/js/mathjax/tex-svg.js"></script> </head>
<body>

<div class="container"><header>
<h1>高新 | AI平台开发工程师</h1><a href="https://github.com/mlcore-engine/mlcore-engine" class="github"><i class="fab fa-github"></i></a>
<p class="description">AI平台开发工程师，专注于AI平台工程和Kubernetes云原生技术。拥有AI平台开发、GPU资源优化和AI服务部署经验</p>

</header>


<div class="content-container">
<main><h1>模型量化基础代码版</h1>
<h1 id="深度学习模型量化完整教程">深度学习模型量化完整教程</h1>
<h2 id="目录">目录</h2>
<ol>
<li><a href="#1-%E9%87%8F%E5%8C%96%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA">量化基础理论</a></li>
<li><a href="#2-%E9%87%8F%E5%8C%96%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86">量化的数学原理</a></li>
<li><a href="#3-%E9%87%8F%E5%8C%96%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3">量化方法详解</a></li>
<li><a href="#4-pytorch%E9%87%8F%E5%8C%96%E5%AE%9E%E6%88%98">PyTorch量化实战</a></li>
<li><a href="#6-%E9%87%8F%E5%8C%96%E6%84%9F%E7%9F%A5%E8%AE%AD%E7%BB%83qat">量化感知训练(QAT)</a></li>
<li><a href="#7-%E9%AB%98%E7%BA%A7%E9%87%8F%E5%8C%96%E6%8A%80%E6%9C%AF">高级量化技术</a></li>
<li><a href="#8-%E9%87%8F%E5%8C%96%E8%B0%83%E8%AF%95%E4%B8%8E%E4%BC%98%E5%8C%96">量化调试与优化</a></li>
<li><a href="#9-%E5%AE%9E%E9%99%85%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90">实际案例分析</a></li>
<li><a href="#10-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">常见问题与解决方案</a></li>
</ol>
<hr>
<h2 id="1-量化基础理论">1. 量化基础理论</h2>
<h3 id="11-什么是模型量化">1.1 什么是模型量化？</h3>
<p>模型量化是将神经网络中的浮点数参数和计算转换为低精度表示的技术。这个过程类似于音频的数字化采样：将连续的模拟信号转换为离散的数字信号。</p>
<h3 id="12-为什么需要量化">1.2 为什么需要量化？</h3>
<h4 id="存储优势">存储优势</h4>
<pre tabindex="0"><code>原始模型 (FP32): 1个参数 = 32位 = 4字节
INT8量化后: 1个参数 = 8位 = 1字节
压缩比: 4:1

示例：
- BERT-Base (110M参数)
  - FP32: 440MB
  - INT8: 110MB
  - INT4: 55MB
</code></pre><h4 id="计算优势">计算优势</h4>
<pre tabindex="0"><code>FP32乘法: 需要专门的浮点运算单元(FPU)
INT8乘法: 可使用更简单的整数运算单元
          支持SIMD指令集加速
          
性能提升: 通常2-4倍
能耗降低: 约10-20倍
</code></pre><h3 id="13-量化的挑战">1.3 量化的挑战</h3>
<ol>
<li><strong>精度损失</strong>: 离散化过程不可避免地引入误差</li>
<li><strong>动态范围</strong>: 不同层的数值范围差异巨大</li>
<li><strong>异常值</strong>: 极端值会影响量化效果</li>
<li><strong>量化噪声</strong>: 累积误差可能导致性能下降</li>
</ol>
<hr>
<h2 id="2-量化的数学原理">2. 量化的数学原理</h2>
<h3 id="21-线性量化的数学表示">2.1 线性量化的数学表示</h3>
<h4 id="基本映射关系">基本映射关系</h4>
<p>将浮点数区间 [α, β] 映射到整数区间 [a, b]：</p>
<pre tabindex="0"><code>量化函数 Q: ℝ → ℤ
Q(x) = round(1/s · (x - z))

反量化函数 Q⁻¹: ℤ → ℝ  
Q⁻¹(x_q) = s · x_q + z

其中：
s (scale): 缩放因子
z (zero-point): 零点偏移
</code></pre><h4 id="参数计算">参数计算</h4>
<p><strong>缩放因子计算：</strong></p>
<pre tabindex="0"><code>s = (β - α) / (b - a)

对于INT8量化：
- 对称量化: s = max(|α|, |β|) / 127
- 非对称量化: s = (β - α) / 255
</code></pre><p><strong>零点计算：</strong></p>
<pre tabindex="0"><code>z = round(a - α/s)

约束条件: a ≤ z ≤ b
</code></pre><h3 id="22-量化误差分析">2.2 量化误差分析</h3>
<h4 id="量化误差定义">量化误差定义</h4>
<pre tabindex="0"><code>ε(x) = Q⁻¹(Q(x)) - x

最大量化误差:
|ε_max| = s/2
</code></pre><h4 id="信噪比snr分析">信噪比(SNR)分析</h4>
<pre tabindex="0"><code>SNR = 10 · log₁₀(P_signal / P_noise)

其中：
P_signal = E[x²]
P_noise = E[ε²] ≈ s²/12 (均匀量化)

理论SNR ≈ 6.02 · b + 1.76 (dB)
b为量化位数
</code></pre><h3 id="23-详细计算示例">2.3 详细计算示例</h3>
<p>假设要量化权重矩阵：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>W <span style="color:#f92672">=</span> [[<span style="color:#ae81ff">2.1</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.3</span>, <span style="color:#ae81ff">0.5</span>],
</span></span><span style="display:flex;"><span>     [<span style="color:#ae81ff">1.8</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">2.7</span>, <span style="color:#ae81ff">0.9</span>],
</span></span><span style="display:flex;"><span>     [<span style="color:#f92672">-</span><span style="color:#ae81ff">0.6</span>, <span style="color:#ae81ff">3.2</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.9</span>]]
</span></span></code></pre></div><p><strong>步骤1: 统计分析</strong></p>
<pre tabindex="0"><code>最小值: α = -2.7
最大值: β = 3.2
范围: R = 5.9
</code></pre><p><strong>步骤2: INT8对称量化</strong></p>
<pre tabindex="0"><code>scale = max(|−2.7|, |3.2|) / 127
      = 3.2 / 127
      = 0.0252

量化过程：
W[0,0]: Q(2.1) = round(2.1 / 0.0252) = round(83.33) = 83
W[0,1]: Q(-1.3) = round(-1.3 / 0.0252) = round(-51.59) = -52
...

量化矩阵：
W_q = [[83, -52, 20],
       [71, -107, 36],
       [-24, 127, -75]]
</code></pre><p><strong>步骤3: 反量化验证</strong></p>
<pre tabindex="0"><code>W&#39;[0,0] = 83 × 0.0252 = 2.092 (误差: 0.008)
W&#39;[0,1] = -52 × 0.0252 = -1.310 (误差: 0.010)
...

均方误差(MSE) = 0.000067
</code></pre><hr>
<h2 id="3-量化方法详解">3. 量化方法详解</h2>
<h3 id="31-均匀量化-vs-非均匀量化">3.1 均匀量化 vs 非均匀量化</h3>
<h4 id="均匀量化">均匀量化</h4>
<p>量化级别均匀分布：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">uniform_quantize</span>(x, num_bits<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>):
</span></span><span style="display:flex;"><span>    qmin <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>(<span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>(num_bits<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>    qmax <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>(num_bits<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    scale <span style="color:#f92672">=</span> (x<span style="color:#f92672">.</span>max() <span style="color:#f92672">-</span> x<span style="color:#f92672">.</span>min()) <span style="color:#f92672">/</span> (qmax <span style="color:#f92672">-</span> qmin)
</span></span><span style="display:flex;"><span>    zero_point <span style="color:#f92672">=</span> qmin <span style="color:#f92672">-</span> round(x<span style="color:#f92672">.</span>min() <span style="color:#f92672">/</span> scale)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    x_q <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>round(x <span style="color:#f92672">/</span> scale <span style="color:#f92672">+</span> zero_point)
</span></span><span style="display:flex;"><span>    x_q <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>clamp(x_q, qmin, qmax)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> x_q, scale, zero_point
</span></span></code></pre></div><h4 id="非均匀量化">非均匀量化</h4>
<p>量化级别根据数据分布调整：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">kmeans_quantize</span>(x, num_clusters<span style="color:#f92672">=</span><span style="color:#ae81ff">256</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 使用K-means聚类找到最优量化级别</span>
</span></span><span style="display:flex;"><span>    x_flat <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>flatten()
</span></span><span style="display:flex;"><span>    kmeans <span style="color:#f92672">=</span> KMeans(n_clusters<span style="color:#f92672">=</span>num_clusters)
</span></span><span style="display:flex;"><span>    kmeans<span style="color:#f92672">.</span>fit(x_flat<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 量化：将每个值映射到最近的聚类中心</span>
</span></span><span style="display:flex;"><span>    labels <span style="color:#f92672">=</span> kmeans<span style="color:#f92672">.</span>predict(x_flat<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>    centers <span style="color:#f92672">=</span> kmeans<span style="color:#f92672">.</span>cluster_centers_
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    x_q <span style="color:#f92672">=</span> centers[labels]<span style="color:#f92672">.</span>reshape(x<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> x_q, centers
</span></span></code></pre></div><h3 id="32-对称量化-vs-非对称量化">3.2 对称量化 vs 非对称量化</h3>
<h4 id="对称量化实现">对称量化实现</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SymmetricQuantizer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, num_bits<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>num_bits <span style="color:#f92672">=</span> num_bits
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>qmax <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>(num_bits<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calculate_scale</span>(self, x):
</span></span><span style="display:flex;"><span>        max_val <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(torch<span style="color:#f92672">.</span>abs(x))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>scale <span style="color:#f92672">=</span> max_val <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>qmax
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>scale
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">quantize</span>(self, x):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>calculate_scale(x)
</span></span><span style="display:flex;"><span>        x_q <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>round(x <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>scale)
</span></span><span style="display:flex;"><span>        x_q <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>clamp(x_q, <span style="color:#f92672">-</span>self<span style="color:#f92672">.</span>qmax, self<span style="color:#f92672">.</span>qmax)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x_q<span style="color:#f92672">.</span>to(torch<span style="color:#f92672">.</span>int8)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">dequantize</span>(self, x_q):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x_q<span style="color:#f92672">.</span>float() <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>scale
</span></span></code></pre></div><h4 id="非对称量化实现">非对称量化实现</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">AsymmetricQuantizer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, num_bits<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>num_bits <span style="color:#f92672">=</span> num_bits
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>qmin <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>qmax <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>num_bits <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calculate_params</span>(self, x):
</span></span><span style="display:flex;"><span>        min_val <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>min(x)
</span></span><span style="display:flex;"><span>        max_val <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(x)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>scale <span style="color:#f92672">=</span> (max_val <span style="color:#f92672">-</span> min_val) <span style="color:#f92672">/</span> (self<span style="color:#f92672">.</span>qmax <span style="color:#f92672">-</span> self<span style="color:#f92672">.</span>qmin)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>zero_point <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>round(self<span style="color:#f92672">.</span>qmin <span style="color:#f92672">-</span> min_val <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>scale)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>zero_point <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>clamp(self<span style="color:#f92672">.</span>zero_point, self<span style="color:#f92672">.</span>qmin, self<span style="color:#f92672">.</span>qmax)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">quantize</span>(self, x):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>calculate_params(x)
</span></span><span style="display:flex;"><span>        x_q <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>round(x <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>scale <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>zero_point)
</span></span><span style="display:flex;"><span>        x_q <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>clamp(x_q, self<span style="color:#f92672">.</span>qmin, self<span style="color:#f92672">.</span>qmax)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x_q<span style="color:#f92672">.</span>to(torch<span style="color:#f92672">.</span>uint8)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">dequantize</span>(self, x_q):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>scale <span style="color:#f92672">*</span> (x_q<span style="color:#f92672">.</span>float() <span style="color:#f92672">-</span> self<span style="color:#f92672">.</span>zero_point)
</span></span></code></pre></div><h3 id="33-动态量化详解">3.3 动态量化详解</h3>
<p>动态量化在运行时计算量化参数：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DynamicQuantizedLinear</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, in_features, out_features):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 存储INT8权重和量化参数</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>register_buffer(<span style="color:#e6db74">&#39;weight_int8&#39;</span>, <span style="color:#66d9ef">None</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>register_buffer(<span style="color:#e6db74">&#39;weight_scale&#39;</span>, <span style="color:#66d9ef">None</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>register_buffer(<span style="color:#e6db74">&#39;weight_zero_point&#39;</span>, <span style="color:#66d9ef">None</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 原始权重用于量化</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(torch<span style="color:#f92672">.</span>randn(out_features, in_features))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bias <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(torch<span style="color:#f92672">.</span>zeros(out_features))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">quantize_weights</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 量化权重（离线进行）</span>
</span></span><span style="display:flex;"><span>        quantizer <span style="color:#f92672">=</span> AsymmetricQuantizer(num_bits<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>weight_int8 <span style="color:#f92672">=</span> quantizer<span style="color:#f92672">.</span>quantize(self<span style="color:#f92672">.</span>weight)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>weight_scale <span style="color:#f92672">=</span> quantizer<span style="color:#f92672">.</span>scale
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>weight_zero_point <span style="color:#f92672">=</span> quantizer<span style="color:#f92672">.</span>zero_point
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 动态量化输入</span>
</span></span><span style="display:flex;"><span>        x_quantizer <span style="color:#f92672">=</span> AsymmetricQuantizer(num_bits<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>)
</span></span><span style="display:flex;"><span>        x_int8 <span style="color:#f92672">=</span> x_quantizer<span style="color:#f92672">.</span>quantize(x)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># INT8矩阵乘法</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 注意：实际实现需要特殊的INT8 GEMM库</span>
</span></span><span style="display:flex;"><span>        output_int32 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>matmul(x_int8<span style="color:#f92672">.</span>int(), self<span style="color:#f92672">.</span>weight_int8<span style="color:#f92672">.</span>int()<span style="color:#f92672">.</span>t())
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 反量化输出</span>
</span></span><span style="display:flex;"><span>        output_scale <span style="color:#f92672">=</span> x_quantizer<span style="color:#f92672">.</span>scale <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>weight_scale
</span></span><span style="display:flex;"><span>        output_zero_point <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>  <span style="color:#75715e"># 简化处理</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        output <span style="color:#f92672">=</span> output_scale <span style="color:#f92672">*</span> output_int32<span style="color:#f92672">.</span>float() <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>bias
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> output
</span></span></code></pre></div><h3 id="34-静态量化详解">3.4 静态量化详解</h3>
<p>静态量化需要校准过程：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">StaticQuantizer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, num_bits<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>, num_bins<span style="color:#f92672">=</span><span style="color:#ae81ff">2048</span>):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>num_bits <span style="color:#f92672">=</span> num_bits
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>num_bins <span style="color:#f92672">=</span> num_bins
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>histogram <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros(num_bins)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>min_val <span style="color:#f92672">=</span> float(<span style="color:#e6db74">&#39;inf&#39;</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>max_val <span style="color:#f92672">=</span> float(<span style="color:#e6db74">&#39;-inf&#39;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">update_stats</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;收集激活值统计信息&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>min_val <span style="color:#f92672">=</span> min(self<span style="color:#f92672">.</span>min_val, x<span style="color:#f92672">.</span>min()<span style="color:#f92672">.</span>item())
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>max_val <span style="color:#f92672">=</span> max(self<span style="color:#f92672">.</span>max_val, x<span style="color:#f92672">.</span>max()<span style="color:#f92672">.</span>item())
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 更新直方图</span>
</span></span><span style="display:flex;"><span>        x_flat <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>flatten()
</span></span><span style="display:flex;"><span>        hist, bin_edges <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>histogram(x_flat, bins<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>num_bins)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>histogram <span style="color:#f92672">+=</span> hist
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calculate_optimal_params</span>(self, method<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;entropy&#39;</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;基于收集的统计信息计算最优量化参数&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> method <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;minmax&#39;</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 简单的最小-最大方法</span>
</span></span><span style="display:flex;"><span>            scale <span style="color:#f92672">=</span> (self<span style="color:#f92672">.</span>max_val <span style="color:#f92672">-</span> self<span style="color:#f92672">.</span>min_val) <span style="color:#f92672">/</span> (<span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>self<span style="color:#f92672">.</span>num_bits <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            zero_point <span style="color:#f92672">=</span> round(<span style="color:#f92672">-</span>self<span style="color:#f92672">.</span>min_val <span style="color:#f92672">/</span> scale)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">elif</span> method <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;entropy&#39;</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># KL散度最小化方法</span>
</span></span><span style="display:flex;"><span>            scale, zero_point <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_minimize_kl_divergence()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">elif</span> method <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;percentile&#39;</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 百分位数方法（去除异常值）</span>
</span></span><span style="display:flex;"><span>            scale, zero_point <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_percentile_calibration(<span style="color:#ae81ff">99.9</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> scale, zero_point
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_minimize_kl_divergence</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;使用KL散度找到最优量化参数&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 实现较复杂，这里是简化版本</span>
</span></span><span style="display:flex;"><span>        best_scale <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>        best_zero_point <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>        min_kl <span style="color:#f92672">=</span> float(<span style="color:#e6db74">&#39;inf&#39;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 尝试不同的量化范围</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> alpha <span style="color:#f92672">in</span> torch<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">1.0</span>, steps<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>):
</span></span><span style="display:flex;"><span>            test_max <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>max_val <span style="color:#f92672">*</span> alpha
</span></span><span style="display:flex;"><span>            test_min <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>min_val <span style="color:#f92672">*</span> alpha
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            scale <span style="color:#f92672">=</span> (test_max <span style="color:#f92672">-</span> test_min) <span style="color:#f92672">/</span> (<span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>self<span style="color:#f92672">.</span>num_bits <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            zero_point <span style="color:#f92672">=</span> round(<span style="color:#f92672">-</span>test_min <span style="color:#f92672">/</span> scale)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 计算KL散度</span>
</span></span><span style="display:flex;"><span>            kl <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_compute_kl(scale, zero_point)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> kl <span style="color:#f92672">&lt;</span> min_kl:
</span></span><span style="display:flex;"><span>                min_kl <span style="color:#f92672">=</span> kl
</span></span><span style="display:flex;"><span>                best_scale <span style="color:#f92672">=</span> scale
</span></span><span style="display:flex;"><span>                best_zero_point <span style="color:#f92672">=</span> zero_point
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> best_scale, best_zero_point
</span></span></code></pre></div><hr>
<h2 id="4-pytorch量化实战">4. PyTorch量化实战</h2>
<h3 id="41-pytorch量化api概览">4.1 PyTorch量化API概览</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.quantization <span style="color:#66d9ef">as</span> tq
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 量化配置</span>
</span></span><span style="display:flex;"><span>qconfig <span style="color:#f92672">=</span> tq<span style="color:#f92672">.</span>QConfig(
</span></span><span style="display:flex;"><span>    activation<span style="color:#f92672">=</span>tq<span style="color:#f92672">.</span>MinMaxObserver<span style="color:#f92672">.</span>with_args(dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>quint8),
</span></span><span style="display:flex;"><span>    weight<span style="color:#f92672">=</span>tq<span style="color:#f92672">.</span>MinMaxObserver<span style="color:#f92672">.</span>with_args(dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>qint8)
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 不同的观察器选项</span>
</span></span><span style="display:flex;"><span>observer_options <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;MinMaxObserver&#39;</span>: tq<span style="color:#f92672">.</span>MinMaxObserver,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;MovingAverageMinMaxObserver&#39;</span>: tq<span style="color:#f92672">.</span>MovingAverageMinMaxObserver,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;HistogramObserver&#39;</span>: tq<span style="color:#f92672">.</span>HistogramObserver,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;PerChannelMinMaxObserver&#39;</span>: tq<span style="color:#f92672">.</span>PerChannelMinMaxObserver
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="42-完整的动态量化示例">4.2 完整的动态量化示例</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision.models <span style="color:#66d9ef">as</span> models
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DynamicQuantizationExample</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">quantize</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;执行动态量化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 指定要量化的层类型</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>quantized_model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>quantize_dynamic(
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>model,
</span></span><span style="display:flex;"><span>            qconfig_spec<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>                nn<span style="color:#f92672">.</span>Linear: torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>default_dynamic_qconfig,
</span></span><span style="display:flex;"><span>                nn<span style="color:#f92672">.</span>LSTM: torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>default_dynamic_qconfig,
</span></span><span style="display:flex;"><span>                nn<span style="color:#f92672">.</span>GRU: torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>default_dynamic_qconfig
</span></span><span style="display:flex;"><span>            },
</span></span><span style="display:flex;"><span>            dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>qint8
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>quantized_model
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compare_models</span>(self, input_data):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;比较量化前后的模型&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 原始模型推理</span>
</span></span><span style="display:flex;"><span>            original_output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model(input_data)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 量化模型推理</span>
</span></span><span style="display:flex;"><span>            quantized_output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quantized_model(input_data)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 计算差异</span>
</span></span><span style="display:flex;"><span>        mse <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mean((original_output <span style="color:#f92672">-</span> quantized_output) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;MSE between outputs: </span><span style="color:#e6db74">{</span>mse<span style="color:#f92672">.</span>item()<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 模型大小比较</span>
</span></span><span style="display:flex;"><span>        original_size <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_get_model_size(self<span style="color:#f92672">.</span>model)
</span></span><span style="display:flex;"><span>        quantized_size <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_get_model_size(self<span style="color:#f92672">.</span>quantized_model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Original model size: </span><span style="color:#e6db74">{</span>original_size<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> MB&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Quantized model size: </span><span style="color:#e6db74">{</span>quantized_size<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> MB&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Compression ratio: </span><span style="color:#e6db74">{</span>original_size<span style="color:#f92672">/</span>quantized_size<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">x&#34;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_get_model_size</span>(self, model):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;计算模型大小（MB）&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        param_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        buffer_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>            param_size <span style="color:#f92672">+=</span> param<span style="color:#f92672">.</span>numel() <span style="color:#f92672">*</span> param<span style="color:#f92672">.</span>element_size()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> buffer <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>buffers():
</span></span><span style="display:flex;"><span>            buffer_size <span style="color:#f92672">+=</span> buffer<span style="color:#f92672">.</span>numel() <span style="color:#f92672">*</span> buffer<span style="color:#f92672">.</span>element_size()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        size_mb <span style="color:#f92672">=</span> (param_size <span style="color:#f92672">+</span> buffer_size) <span style="color:#f92672">/</span> <span style="color:#ae81ff">1024</span> <span style="color:#f92672">/</span> <span style="color:#ae81ff">1024</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> size_mb
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">benchmark_speed</span>(self, input_data, num_runs<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;性能对比测试&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 预热</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>            _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model(input_data)
</span></span><span style="display:flex;"><span>            _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quantized_model(input_data)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 原始模型计时</span>
</span></span><span style="display:flex;"><span>        start <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(num_runs):
</span></span><span style="display:flex;"><span>            _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model(input_data)
</span></span><span style="display:flex;"><span>        original_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> start
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 量化模型计时</span>
</span></span><span style="display:flex;"><span>        start <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(num_runs):
</span></span><span style="display:flex;"><span>            _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quantized_model(input_data)
</span></span><span style="display:flex;"><span>        quantized_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> start
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Original model: </span><span style="color:#e6db74">{</span>original_time<span style="color:#e6db74">:</span><span style="color:#e6db74">.3f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">s&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Quantized model: </span><span style="color:#e6db74">{</span>quantized_time<span style="color:#e6db74">:</span><span style="color:#e6db74">.3f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">s&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Speedup: </span><span style="color:#e6db74">{</span>original_time<span style="color:#f92672">/</span>quantized_time<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">x&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 使用示例</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>resnet18(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>quantizer <span style="color:#f92672">=</span> DynamicQuantizationExample(model)
</span></span><span style="display:flex;"><span>quantized_model <span style="color:#f92672">=</span> quantizer<span style="color:#f92672">.</span>quantize()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 测试</span>
</span></span><span style="display:flex;"><span>dummy_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)
</span></span><span style="display:flex;"><span>quantizer<span style="color:#f92672">.</span>compare_models(dummy_input)
</span></span><span style="display:flex;"><span>quantizer<span style="color:#f92672">.</span>benchmark_speed(dummy_input)
</span></span></code></pre></div><h3 id="43-静态量化完整流程">4.3 静态量化完整流程</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">StaticQuantizationPipeline</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model, calibration_loader):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>calibration_loader <span style="color:#f92672">=</span> calibration_loader
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">prepare_model</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;准备模型进行量化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 1. 设置量化配置</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>qconfig <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>get_default_qconfig(<span style="color:#e6db74">&#39;fbgemm&#39;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 2. 准备模型（插入观察器）</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>prepared_model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>prepare(self<span style="color:#f92672">.</span>model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>prepared_model
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calibrate</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;使用代表性数据校准模型&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;Calibrating model...&#34;</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>prepared_model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> batch_idx, (data, target) <span style="color:#f92672">in</span> enumerate(self<span style="color:#f92672">.</span>calibration_loader):
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>prepared_model(data)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> batch_idx <span style="color:#f92672">%</span> <span style="color:#ae81ff">10</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>                    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Calibration batch </span><span style="color:#e6db74">{</span>batch_idx<span style="color:#e6db74">}</span><span style="color:#e6db74">/</span><span style="color:#e6db74">{</span>len(self<span style="color:#f92672">.</span>calibration_loader)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 通常使用100-1000个batch进行校准</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> batch_idx <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">100</span>:
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;Calibration complete!&#34;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">convert</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;转换为量化模型&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>quantized_model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>convert(self<span style="color:#f92672">.</span>prepared_model)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>quantized_model
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">evaluate_accuracy</span>(self, test_loader):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;评估量化模型精度&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        correct <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        total <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>quantized_model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> data, target <span style="color:#f92672">in</span> test_loader:
</span></span><span style="display:flex;"><span>                output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quantized_model(data)
</span></span><span style="display:flex;"><span>                _, predicted <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(output<span style="color:#f92672">.</span>data, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>                total <span style="color:#f92672">+=</span> target<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>                correct <span style="color:#f92672">+=</span> (predicted <span style="color:#f92672">==</span> target)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        accuracy <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span> <span style="color:#f92672">*</span> correct <span style="color:#f92672">/</span> total
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Quantized Model Accuracy: </span><span style="color:#e6db74">{</span>accuracy<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">%&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> accuracy
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">full_pipeline</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;执行完整的静态量化流程&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 1. 准备</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>prepare_model()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 2. 校准</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>calibrate()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 3. 转换</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>convert()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 4. 保存量化模型</span>
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>save(self<span style="color:#f92672">.</span>quantized_model<span style="color:#f92672">.</span>state_dict(), <span style="color:#e6db74">&#39;quantized_model.pth&#39;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 5. 也可以使用TorchScript保存</span>
</span></span><span style="display:flex;"><span>        scripted_quantized_model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>script(self<span style="color:#f92672">.</span>quantized_model)
</span></span><span style="display:flex;"><span>        scripted_quantized_model<span style="color:#f92672">.</span>save(<span style="color:#e6db74">&#39;quantized_model_scripted.pth&#39;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>quantized_model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 自定义量化模块示例</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">QuantizableConvNet</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>quant <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>QuantStub()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dequant <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>DeQuantStub()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bn1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">32</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>relu1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ReLU()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bn2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">64</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>relu2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ReLU()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">64</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">8</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 量化输入</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quant(x)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 主要计算</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>relu1(self<span style="color:#f92672">.</span>bn1(self<span style="color:#f92672">.</span>conv1(x)))
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>relu2(self<span style="color:#f92672">.</span>bn2(self<span style="color:#f92672">.</span>conv2(x)))
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>functional<span style="color:#f92672">.</span>avg_pool2d(x, x<span style="color:#f92672">.</span>size()[<span style="color:#ae81ff">2</span>:])
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(x<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc(x)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 反量化输出</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dequant(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fuse_modules</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;融合可以合并的层&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>fuse_modules(self, [
</span></span><span style="display:flex;"><span>            [<span style="color:#e6db74">&#39;conv1&#39;</span>, <span style="color:#e6db74">&#39;bn1&#39;</span>, <span style="color:#e6db74">&#39;relu1&#39;</span>],
</span></span><span style="display:flex;"><span>            [<span style="color:#e6db74">&#39;conv2&#39;</span>, <span style="color:#e6db74">&#39;bn2&#39;</span>, <span style="color:#e6db74">&#39;relu2&#39;</span>]
</span></span><span style="display:flex;"><span>        ], inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span></code></pre></div><h3 id="44-post-training量化优化技巧">4.4 Post-Training量化优化技巧</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">AdvancedQuantizationTechniques</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> model
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">bias_correction</span>(self, calibration_loader):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;偏差校正技术&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 收集原始模型和量化模型的输出</span>
</span></span><span style="display:flex;"><span>        original_outputs <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        quantized_outputs <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        quantized_model <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quantize_model()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> data, _ <span style="color:#f92672">in</span> calibration_loader:
</span></span><span style="display:flex;"><span>                original_outputs<span style="color:#f92672">.</span>append(self<span style="color:#f92672">.</span>model(data))
</span></span><span style="display:flex;"><span>                quantized_outputs<span style="color:#f92672">.</span>append(quantized_model(data))
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 计算并校正偏差</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> quantized_model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(module, nn<span style="color:#f92672">.</span>Conv2d) <span style="color:#f92672">or</span> isinstance(module, nn<span style="color:#f92672">.</span>Linear):
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 计算平均偏差</span>
</span></span><span style="display:flex;"><span>                bias_correction <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_compute_bias_correction(
</span></span><span style="display:flex;"><span>                    original_outputs, quantized_outputs, name
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 应用偏差校正</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> module<span style="color:#f92672">.</span>bias <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>                    module<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data <span style="color:#f92672">+=</span> bias_correction
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                    module<span style="color:#f92672">.</span>bias <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(bias_correction)
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">equalization</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;权重均衡化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 找到连续的Conv/Linear层</span>
</span></span><span style="display:flex;"><span>        consecutive_layers <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_find_consecutive_layers()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> layer1, layer2 <span style="color:#f92672">in</span> consecutive_layers:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 计算均衡化因子</span>
</span></span><span style="display:flex;"><span>            scale_factor <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_compute_equalization_scale(layer1, layer2)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 应用均衡化</span>
</span></span><span style="display:flex;"><span>            layer1<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data <span style="color:#f92672">*=</span> scale_factor<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            layer2<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data <span style="color:#f92672">/=</span> scale_factor<span style="color:#f92672">.</span>view(<span style="color:#ae81ff">1</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> layer1<span style="color:#f92672">.</span>bias <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>                layer1<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data <span style="color:#f92672">*=</span> scale_factor
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">outlier_channel_splitting</span>(self, threshold<span style="color:#f92672">=</span><span style="color:#ae81ff">3.0</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;异常通道分割&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(module, nn<span style="color:#f92672">.</span>Conv2d):
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 计算每个通道的统计信息</span>
</span></span><span style="display:flex;"><span>                channel_max <span style="color:#f92672">=</span> module<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>abs()<span style="color:#f92672">.</span>view(
</span></span><span style="display:flex;"><span>                    module<span style="color:#f92672">.</span>out_channels, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>                )<span style="color:#f92672">.</span>max(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                mean <span style="color:#f92672">=</span> channel_max<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>                std <span style="color:#f92672">=</span> channel_max<span style="color:#f92672">.</span>std()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 识别异常通道</span>
</span></span><span style="display:flex;"><span>                outlier_mask <span style="color:#f92672">=</span> channel_max <span style="color:#f92672">&gt;</span> (mean <span style="color:#f92672">+</span> threshold <span style="color:#f92672">*</span> std)
</span></span><span style="display:flex;"><span>                outlier_indices <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>where(outlier_mask)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> len(outlier_indices) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>                    <span style="color:#75715e"># 分割异常通道</span>
</span></span><span style="display:flex;"><span>                    self<span style="color:#f92672">.</span>_split_outlier_channels(module, outlier_indices)
</span></span></code></pre></div><hr>
<h2 id="5-量化感知训练qat深入">5. 量化感知训练(QAT)深入</h2>
<h3 id="51-qat的理论基础">5.1 QAT的理论基础</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">FakeQuantize</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;假量化操作的实现&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, observer, quant_min<span style="color:#f92672">=-</span><span style="color:#ae81ff">128</span>, quant_max<span style="color:#f92672">=</span><span style="color:#ae81ff">127</span>, 
</span></span><span style="display:flex;"><span>                 learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>, symmetric<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>observer <span style="color:#f92672">=</span> observer
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>quant_min <span style="color:#f92672">=</span> quant_min
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>quant_max <span style="color:#f92672">=</span> quant_max
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>learning_rate <span style="color:#f92672">=</span> learning_rate
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>symmetric <span style="color:#f92672">=</span> symmetric
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 可学习的量化参数</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>register_buffer(<span style="color:#e6db74">&#39;scale&#39;</span>, torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1.0</span>]))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>register_buffer(<span style="color:#e6db74">&#39;zero_point&#39;</span>, torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">0</span>]))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>register_buffer(<span style="color:#e6db74">&#39;fake_quant_enabled&#39;</span>, torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>]))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>training:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 训练时更新统计信息</span>
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>observer(x)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 计算量化参数</span>
</span></span><span style="display:flex;"><span>            scale, zero_point <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>observer<span style="color:#f92672">.</span>calculate_qparams()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 使用指数移动平均更新</span>
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>scale <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>scale <span style="color:#f92672">*</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> self<span style="color:#f92672">.</span>learning_rate) <span style="color:#f92672">+</span> \
</span></span><span style="display:flex;"><span>                        scale <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>learning_rate
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>zero_point <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>zero_point <span style="color:#f92672">*</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> self<span style="color:#f92672">.</span>learning_rate) <span style="color:#f92672">+</span> \
</span></span><span style="display:flex;"><span>                            zero_point <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>learning_rate
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>fake_quant_enabled[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 执行假量化</span>
</span></span><span style="display:flex;"><span>            x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fake_quantize(x)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fake_quantize</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;假量化的前向和反向传播&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 量化</span>
</span></span><span style="display:flex;"><span>        x_int <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>round(x <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>scale <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>zero_point)
</span></span><span style="display:flex;"><span>        x_int <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>clamp(x_int, self<span style="color:#f92672">.</span>quant_min, self<span style="color:#f92672">.</span>quant_max)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 反量化</span>
</span></span><span style="display:flex;"><span>        x_quant <span style="color:#f92672">=</span> (x_int <span style="color:#f92672">-</span> self<span style="color:#f92672">.</span>zero_point) <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>scale
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 直通估计器(STE)用于梯度</span>
</span></span><span style="display:flex;"><span>        x_quant <span style="color:#f92672">=</span> x <span style="color:#f92672">+</span> (x_quant <span style="color:#f92672">-</span> x)<span style="color:#f92672">.</span>detach()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x_quant
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">@torch.jit.export</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">extra_repr</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;quant_min=</span><span style="color:#e6db74">{</span>self<span style="color:#f92672">.</span>quant_min<span style="color:#e6db74">}</span><span style="color:#e6db74">, quant_max=</span><span style="color:#e6db74">{</span>self<span style="color:#f92672">.</span>quant_max<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>
</span></span></code></pre></div><h3 id="52-自定义qat训练循环">5.2 自定义QAT训练循环</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">QATTrainer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model, train_loader, val_loader):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>train_loader <span style="color:#f92672">=</span> train_loader
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>val_loader <span style="color:#f92672">=</span> val_loader
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">prepare_qat</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;准备模型进行QAT&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 1. 定义量化配置</span>
</span></span><span style="display:flex;"><span>        qat_config <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>QConfig(
</span></span><span style="display:flex;"><span>            activation<span style="color:#f92672">=</span>FakeQuantize<span style="color:#f92672">.</span>with_args(
</span></span><span style="display:flex;"><span>                observer<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>MovingAverageMinMaxObserver,
</span></span><span style="display:flex;"><span>                quant_min<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>                quant_max<span style="color:#f92672">=</span><span style="color:#ae81ff">255</span>,
</span></span><span style="display:flex;"><span>                dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>quint8,
</span></span><span style="display:flex;"><span>                qscheme<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>per_tensor_affine
</span></span><span style="display:flex;"><span>            ),
</span></span><span style="display:flex;"><span>            weight<span style="color:#f92672">=</span>FakeQuantize<span style="color:#f92672">.</span>with_args(
</span></span><span style="display:flex;"><span>                observer<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>MovingAveragePerChannelMinMaxObserver,
</span></span><span style="display:flex;"><span>                quant_min<span style="color:#f92672">=-</span><span style="color:#ae81ff">128</span>,
</span></span><span style="display:flex;"><span>                quant_max<span style="color:#f92672">=</span><span style="color:#ae81ff">127</span>,
</span></span><span style="display:flex;"><span>                dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>qint8,
</span></span><span style="display:flex;"><span>                qscheme<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>per_channel_symmetric
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 2. 应用配置</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>qconfig <span style="color:#f92672">=</span> qat_config
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 3. 准备模型</span>
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>prepare_qat(self<span style="color:#f92672">.</span>model, inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train_epoch</span>(self, optimizer, criterion):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;训练一个epoch&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>        total_loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        correct <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        total <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> batch_idx, (data, target) <span style="color:#f92672">in</span> enumerate(self<span style="color:#f92672">.</span>train_loader):
</span></span><span style="display:flex;"><span>            optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model(data)
</span></span><span style="display:flex;"><span>            loss <span style="color:#f92672">=</span> criterion(output, target)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>            optimizer<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            total_loss <span style="color:#f92672">+=</span> loss<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>            _, predicted <span style="color:#f92672">=</span> output<span style="color:#f92672">.</span>max(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            total <span style="color:#f92672">+=</span> target<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>            correct <span style="color:#f92672">+=</span> predicted<span style="color:#f92672">.</span>eq(target)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> batch_idx <span style="color:#f92672">%</span> <span style="color:#ae81ff">100</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Batch </span><span style="color:#e6db74">{</span>batch_idx<span style="color:#e6db74">}</span><span style="color:#e6db74">/</span><span style="color:#e6db74">{</span>len(self<span style="color:#f92672">.</span>train_loader)<span style="color:#e6db74">}</span><span style="color:#e6db74">, &#39;</span>
</span></span><span style="display:flex;"><span>                      <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Loss: </span><span style="color:#e6db74">{</span>loss<span style="color:#f92672">.</span>item()<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, &#39;</span>
</span></span><span style="display:flex;"><span>                      <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Acc: </span><span style="color:#e6db74">{</span><span style="color:#ae81ff">100.</span><span style="color:#f92672">*</span>correct<span style="color:#f92672">/</span>total<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">%&#39;</span>)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> total_loss <span style="color:#f92672">/</span> len(self<span style="color:#f92672">.</span>train_loader), <span style="color:#ae81ff">100.</span> <span style="color:#f92672">*</span> correct <span style="color:#f92672">/</span> total
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">validate</span>(self, criterion):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;验证模型&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        total_loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        correct <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        total <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> data, target <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>val_loader:
</span></span><span style="display:flex;"><span>                output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model(data)
</span></span><span style="display:flex;"><span>                loss <span style="color:#f92672">=</span> criterion(output, target)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                total_loss <span style="color:#f92672">+=</span> loss<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>                _, predicted <span style="color:#f92672">=</span> output<span style="color:#f92672">.</span>max(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>                total <span style="color:#f92672">+=</span> target<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>                correct <span style="color:#f92672">+=</span> predicted<span style="color:#f92672">.</span>eq(target)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> total_loss <span style="color:#f92672">/</span> len(self<span style="color:#f92672">.</span>val_loader), <span style="color:#ae81ff">100.</span> <span style="color:#f92672">*</span> correct <span style="color:#f92672">/</span> total
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train_qat</span>(self, epochs, lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;完整的QAT训练流程&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 准备QAT</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>prepare_qat()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 优化器和损失函数</span>
</span></span><span style="display:flex;"><span>        optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>parameters(), lr<span style="color:#f92672">=</span>lr)
</span></span><span style="display:flex;"><span>        criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 学习率调度器</span>
</span></span><span style="display:flex;"><span>        scheduler <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>lr_scheduler<span style="color:#f92672">.</span>CosineAnnealingLR(
</span></span><span style="display:flex;"><span>            optimizer, T_max<span style="color:#f92672">=</span>epochs
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 训练循环</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epochs):
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Epoch </span><span style="color:#e6db74">{</span>epoch<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">/</span><span style="color:#e6db74">{</span>epochs<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 逐步启用量化</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> epoch <span style="color:#f92672">&lt;</span> epochs <span style="color:#f92672">//</span> <span style="color:#ae81ff">4</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 前25%只训练，不量化</span>
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>disable_fake_quant()
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">elif</span> epoch <span style="color:#f92672">&lt;</span> epochs <span style="color:#f92672">//</span> <span style="color:#ae81ff">2</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 25%-50%只量化权重</span>
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>enable_weight_fake_quant()
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 50%-100%完全量化</span>
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>enable_all_fake_quant()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 训练</span>
</span></span><span style="display:flex;"><span>            train_loss, train_acc <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>train_epoch(optimizer, criterion)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 验证</span>
</span></span><span style="display:flex;"><span>            val_loss, val_acc <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>validate(criterion)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Train Loss: </span><span style="color:#e6db74">{</span>train_loss<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, Train Acc: </span><span style="color:#e6db74">{</span>train_acc<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">%&#39;</span>)
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Val Loss: </span><span style="color:#e6db74">{</span>val_loss<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, Val Acc: </span><span style="color:#e6db74">{</span>val_acc<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">%&#39;</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            scheduler<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 转换为量化模型</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>quantized_model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>convert(self<span style="color:#f92672">.</span>model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>quantized_model
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">disable_fake_quant</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;禁用假量化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(module, FakeQuantize):
</span></span><span style="display:flex;"><span>                module<span style="color:#f92672">.</span>fake_quant_enabled[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">enable_weight_fake_quant</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;只启用权重假量化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(module, FakeQuantize):
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> <span style="color:#e6db74">&#39;weight&#39;</span> <span style="color:#f92672">in</span> name:
</span></span><span style="display:flex;"><span>                    module<span style="color:#f92672">.</span>fake_quant_enabled[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                    module<span style="color:#f92672">.</span>fake_quant_enabled[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">enable_all_fake_quant</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;启用所有假量化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(module, FakeQuantize):
</span></span><span style="display:flex;"><span>                module<span style="color:#f92672">.</span>fake_quant_enabled[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span></code></pre></div><h3 id="53-qat高级技巧">5.3 QAT高级技巧</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">AdvancedQATTechniques</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> model
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">distillation_qat</span>(self, teacher_model, temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">4.0</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;知识蒸馏辅助的QAT&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DistillationLoss</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">def</span> __init__(self, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.7</span>, temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">4.0</span>):
</span></span><span style="display:flex;"><span>                super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>alpha <span style="color:#f92672">=</span> alpha
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>temperature <span style="color:#f92672">=</span> temperature
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss()
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>kl_div <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>KLDivLoss(reduction<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;batchmean&#39;</span>)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, student_output, labels, teacher_output):
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 标准分类损失</span>
</span></span><span style="display:flex;"><span>                ce_loss <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>criterion(student_output, labels)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 蒸馏损失</span>
</span></span><span style="display:flex;"><span>                student_logits <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>log_softmax(
</span></span><span style="display:flex;"><span>                    student_output <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>temperature, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>                teacher_logits <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>softmax(
</span></span><span style="display:flex;"><span>                    teacher_output <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>temperature, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>                distillation_loss <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>kl_div(student_logits, teacher_logits)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 组合损失</span>
</span></span><span style="display:flex;"><span>                loss <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>alpha <span style="color:#f92672">*</span> ce_loss <span style="color:#f92672">+</span> \
</span></span><span style="display:flex;"><span>                       (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> self<span style="color:#f92672">.</span>alpha) <span style="color:#f92672">*</span> distillation_loss <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>temperature <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">return</span> loss, ce_loss, distillation_loss
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> DistillationLoss(temperature<span style="color:#f92672">=</span>temperature)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">progressive_quantization</span>(self, bit_schedule):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;渐进式量化：从高位到低位&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> epoch, num_bits <span style="color:#f92672">in</span> bit_schedule<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Epoch </span><span style="color:#e6db74">{</span>epoch<span style="color:#e6db74">}</span><span style="color:#e6db74">: Switching to </span><span style="color:#e6db74">{</span>num_bits<span style="color:#e6db74">}</span><span style="color:#e6db74">-bit quantization&#34;</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 更新所有量化器的位数</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>modules():
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> hasattr(module, <span style="color:#e6db74">&#39;weight_fake_quant&#39;</span>):
</span></span><span style="display:flex;"><span>                    <span style="color:#75715e"># 更新权重量化器</span>
</span></span><span style="display:flex;"><span>                    module<span style="color:#f92672">.</span>weight_fake_quant<span style="color:#f92672">.</span>quant_min <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>(<span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>(num_bits<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>                    module<span style="color:#f92672">.</span>weight_fake_quant<span style="color:#f92672">.</span>quant_max <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>(num_bits<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> hasattr(module, <span style="color:#e6db74">&#39;activation_fake_quant&#39;</span>):
</span></span><span style="display:flex;"><span>                    <span style="color:#75715e"># 更新激活量化器</span>
</span></span><span style="display:flex;"><span>                    module<span style="color:#f92672">.</span>activation_fake_quant<span style="color:#f92672">.</span>quant_min <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>                    module<span style="color:#f92672">.</span>activation_fake_quant<span style="color:#f92672">.</span>quant_max <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>num_bits <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">mixed_precision_qat</span>(self, bit_config):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;混合精度QAT：不同层使用不同位数&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> name <span style="color:#f92672">in</span> bit_config:
</span></span><span style="display:flex;"><span>                num_bits <span style="color:#f92672">=</span> bit_config[name]
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 为该层设置特定的量化配置</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> isinstance(module, (nn<span style="color:#f92672">.</span>Conv2d, nn<span style="color:#f92672">.</span>Linear)):
</span></span><span style="display:flex;"><span>                    module<span style="color:#f92672">.</span>qconfig <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_get_qconfig_for_bits(num_bits)
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_get_qconfig_for_bits</span>(self, num_bits):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;根据位数返回相应的量化配置&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> num_bits <span style="color:#f92672">==</span> <span style="color:#ae81ff">8</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>default_qat_qconfig
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">elif</span> num_bits <span style="color:#f92672">==</span> <span style="color:#ae81ff">4</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 4位量化配置</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>QConfig(
</span></span><span style="display:flex;"><span>                activation<span style="color:#f92672">=</span>FakeQuantize<span style="color:#f92672">.</span>with_args(
</span></span><span style="display:flex;"><span>                    observer<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>MinMaxObserver,
</span></span><span style="display:flex;"><span>                    quant_min<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>                    quant_max<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>,
</span></span><span style="display:flex;"><span>                    dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>quint8
</span></span><span style="display:flex;"><span>                ),
</span></span><span style="display:flex;"><span>                weight<span style="color:#f92672">=</span>FakeQuantize<span style="color:#f92672">.</span>with_args(
</span></span><span style="display:flex;"><span>                    observer<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>MinMaxObserver,
</span></span><span style="display:flex;"><span>                    quant_min<span style="color:#f92672">=-</span><span style="color:#ae81ff">8</span>,
</span></span><span style="display:flex;"><span>                    quant_max<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>                    dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>qint8
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">raise</span> <span style="color:#a6e22e">ValueError</span>(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Unsupported bit width: </span><span style="color:#e6db74">{</span>num_bits<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><hr>
<h2 id="6-高级量化技术">6. 高级量化技术</h2>
<h3 id="61-向量量化vector-quantization">6.1 向量量化(Vector Quantization)</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">VectorQuantizer</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;向量量化器实现&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, num_embeddings, embedding_dim, commitment_cost<span style="color:#f92672">=</span><span style="color:#ae81ff">0.25</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>num_embeddings <span style="color:#f92672">=</span> num_embeddings
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>embedding_dim <span style="color:#f92672">=</span> embedding_dim
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>commitment_cost <span style="color:#f92672">=</span> commitment_cost
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 码本（codebook）</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>embeddings <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Embedding(num_embeddings, embedding_dim)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>embeddings<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>uniform_(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>num_embeddings, <span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>num_embeddings)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, inputs):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 输入形状: [B, C, H, W]</span>
</span></span><span style="display:flex;"><span>        input_shape <span style="color:#f92672">=</span> inputs<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 展平</span>
</span></span><span style="display:flex;"><span>        flat_input <span style="color:#f92672">=</span> inputs<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, self<span style="color:#f92672">.</span>embedding_dim)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 计算到每个码本向量的距离</span>
</span></span><span style="display:flex;"><span>        distances <span style="color:#f92672">=</span> (torch<span style="color:#f92672">.</span>sum(flat_input<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, keepdim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>) 
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">+</span> torch<span style="color:#f92672">.</span>sum(self<span style="color:#f92672">.</span>embeddings<span style="color:#f92672">.</span>weight<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">-</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> torch<span style="color:#f92672">.</span>matmul(flat_input, self<span style="color:#f92672">.</span>embeddings<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>t()))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 找到最近的码本索引</span>
</span></span><span style="display:flex;"><span>        encoding_indices <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>argmin(distances, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        encodings <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros(encoding_indices<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>], self<span style="color:#f92672">.</span>num_embeddings)
</span></span><span style="display:flex;"><span>        encodings<span style="color:#f92672">.</span>scatter_(<span style="color:#ae81ff">1</span>, encoding_indices, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 量化</span>
</span></span><span style="display:flex;"><span>        quantized <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>matmul(encodings, self<span style="color:#f92672">.</span>embeddings<span style="color:#f92672">.</span>weight)<span style="color:#f92672">.</span>view(input_shape)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 计算VQ损失</span>
</span></span><span style="display:flex;"><span>        e_latent_loss <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>mse_loss(quantized<span style="color:#f92672">.</span>detach(), inputs)
</span></span><span style="display:flex;"><span>        q_latent_loss <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>mse_loss(quantized, inputs<span style="color:#f92672">.</span>detach())
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> q_latent_loss <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>commitment_cost <span style="color:#f92672">*</span> e_latent_loss
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 直通估计器</span>
</span></span><span style="display:flex;"><span>        quantized <span style="color:#f92672">=</span> inputs <span style="color:#f92672">+</span> (quantized <span style="color:#f92672">-</span> inputs)<span style="color:#f92672">.</span>detach()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> quantized, loss, encodings
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_codebook_usage</span>(self, encodings_list):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;分析码本使用情况&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        usage <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros(self<span style="color:#f92672">.</span>num_embeddings)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> encodings <span style="color:#f92672">in</span> encodings_list:
</span></span><span style="display:flex;"><span>            usage <span style="color:#f92672">+=</span> encodings<span style="color:#f92672">.</span>sum(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> usage <span style="color:#f92672">/</span> len(encodings_list)
</span></span></code></pre></div><h3 id="62-product-quantization">6.2 Product Quantization</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ProductQuantizer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;乘积量化实现&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, dim, num_subvectors, num_centroids):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dim <span style="color:#f92672">=</span> dim
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>num_subvectors <span style="color:#f92672">=</span> num_subvectors
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>num_centroids <span style="color:#f92672">=</span> num_centroids
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>subvector_dim <span style="color:#f92672">=</span> dim <span style="color:#f92672">//</span> num_subvectors
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 每个子向量的码本</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>codebooks <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fit</span>(self, data, n_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;训练量化器&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        n_samples <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 将数据分割成子向量</span>
</span></span><span style="display:flex;"><span>        data_subvectors <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>reshape(n_samples, self<span style="color:#f92672">.</span>num_subvectors, 
</span></span><span style="display:flex;"><span>                                      self<span style="color:#f92672">.</span>subvector_dim)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 为每个子向量训练码本</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(self<span style="color:#f92672">.</span>num_subvectors):
</span></span><span style="display:flex;"><span>            subvector_data <span style="color:#f92672">=</span> data_subvectors[:, i, :]
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 使用K-means聚类</span>
</span></span><span style="display:flex;"><span>            codebook <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_kmeans(subvector_data, self<span style="color:#f92672">.</span>num_centroids, n_iter)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>codebooks<span style="color:#f92672">.</span>append(codebook)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">encode</span>(self, data):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;编码数据&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        n_samples <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>        codes <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((n_samples, self<span style="color:#f92672">.</span>num_subvectors), dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int32)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        data_subvectors <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>reshape(n_samples, self<span style="color:#f92672">.</span>num_subvectors, 
</span></span><span style="display:flex;"><span>                                      self<span style="color:#f92672">.</span>subvector_dim)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(self<span style="color:#f92672">.</span>num_subvectors):
</span></span><span style="display:flex;"><span>            subvector_data <span style="color:#f92672">=</span> data_subvectors[:, i, :]
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 找到最近的码字</span>
</span></span><span style="display:flex;"><span>            distances <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_compute_distances(subvector_data, self<span style="color:#f92672">.</span>codebooks[i])
</span></span><span style="display:flex;"><span>            codes[:, i] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmin(distances, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> codes
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">decode</span>(self, codes):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;解码数据&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        n_samples <span style="color:#f92672">=</span> codes<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>        reconstructed <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((n_samples, self<span style="color:#f92672">.</span>dim))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(self<span style="color:#f92672">.</span>num_subvectors):
</span></span><span style="display:flex;"><span>            start_idx <span style="color:#f92672">=</span> i <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>subvector_dim
</span></span><span style="display:flex;"><span>            end_idx <span style="color:#f92672">=</span> (i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>) <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>subvector_dim
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 从码本中检索</span>
</span></span><span style="display:flex;"><span>            reconstructed[:, start_idx:end_idx] <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>codebooks[i][codes[:, i]]
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> reconstructed
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_kmeans</span>(self, data, k, n_iter):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;简化的K-means实现&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        n_samples <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 随机初始化中心点</span>
</span></span><span style="display:flex;"><span>        indices <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>choice(n_samples, k, replace<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        centers <span style="color:#f92672">=</span> data[indices]<span style="color:#f92672">.</span>copy()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(n_iter):
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 分配到最近的中心</span>
</span></span><span style="display:flex;"><span>            distances <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_compute_distances(data, centers)
</span></span><span style="display:flex;"><span>            labels <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmin(distances, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 更新中心点</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(k):
</span></span><span style="display:flex;"><span>                mask <span style="color:#f92672">=</span> labels <span style="color:#f92672">==</span> i
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> mask<span style="color:#f92672">.</span>any():
</span></span><span style="display:flex;"><span>                    centers[i] <span style="color:#f92672">=</span> data[mask]<span style="color:#f92672">.</span>mean(axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> centers
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_compute_distances</span>(self, X, Y):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;计算欧氏距离&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>sum((X[:, np<span style="color:#f92672">.</span>newaxis] <span style="color:#f92672">-</span> Y[np<span style="color:#f92672">.</span>newaxis]) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span></code></pre></div><h3 id="63-学习型量化">6.3 学习型量化</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">LearnedStepSizeQuantization</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;LSQ: Learned Step Size Quantization&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, num_bits<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>, symmetric<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, per_channel<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>num_bits <span style="color:#f92672">=</span> num_bits
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>symmetric <span style="color:#f92672">=</span> symmetric
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>per_channel <span style="color:#f92672">=</span> per_channel
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> symmetric:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>Qn <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>(<span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>(num_bits<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>Qp <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>(num_bits<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>Qn <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>Qp <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>num_bits <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">init_scale</span>(self, x, num_channels<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;初始化可学习的scale参数&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>per_channel:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 每通道scale</span>
</span></span><span style="display:flex;"><span>            x_flat <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(num_channels, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            mean <span style="color:#f92672">=</span> x_flat<span style="color:#f92672">.</span>mean(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            std <span style="color:#f92672">=</span> x_flat<span style="color:#f92672">.</span>std(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 初始scale设置为 2*std / sqrt(Qp)</span>
</span></span><span style="display:flex;"><span>            init_scale <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> std <span style="color:#f92672">/</span> math<span style="color:#f92672">.</span>sqrt(self<span style="color:#f92672">.</span>Qp)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>scale <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(init_scale<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 全局scale</span>
</span></span><span style="display:flex;"><span>            mean <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>            std <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>std()
</span></span><span style="display:flex;"><span>            init_scale <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> std <span style="color:#f92672">/</span> math<span style="color:#f92672">.</span>sqrt(self<span style="color:#f92672">.</span>Qp)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>scale <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(torch<span style="color:#f92672">.</span>tensor(init_scale))
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> hasattr(self, <span style="color:#e6db74">&#39;scale&#39;</span>):
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>init_scale(x, x<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>per_channel <span style="color:#66d9ef">else</span> <span style="color:#66d9ef">None</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 梯度缩放因子</span>
</span></span><span style="display:flex;"><span>        grad_scale <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span> <span style="color:#f92672">/</span> math<span style="color:#f92672">.</span>sqrt(x<span style="color:#f92672">.</span>numel() <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>Qp)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 缩放梯度</span>
</span></span><span style="display:flex;"><span>        scale <span style="color:#f92672">=</span> grad_scale <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>scale
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 量化</span>
</span></span><span style="display:flex;"><span>        x_scaled <span style="color:#f92672">=</span> x <span style="color:#f92672">/</span> scale
</span></span><span style="display:flex;"><span>        x_quant <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>round(torch<span style="color:#f92672">.</span>clamp(x_scaled, self<span style="color:#f92672">.</span>Qn, self<span style="color:#f92672">.</span>Qp))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 反量化</span>
</span></span><span style="display:flex;"><span>        x_dequant <span style="color:#f92672">=</span> x_quant <span style="color:#f92672">*</span> scale
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># STE</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x <span style="color:#f92672">+</span> (x_dequant <span style="color:#f92672">-</span> x)<span style="color:#f92672">.</span>detach()
</span></span></code></pre></div><h3 id="64-二值化和三值化">6.4 二值化和三值化</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">BinaryQuantization</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;二值量化：+1/-1&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 使用符号函数</span>
</span></span><span style="display:flex;"><span>        x_binary <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>sign(x)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># STE用于反向传播</span>
</span></span><span style="display:flex;"><span>        x_binary <span style="color:#f92672">=</span> x <span style="color:#f92672">+</span> (x_binary <span style="color:#f92672">-</span> x)<span style="color:#f92672">.</span>detach()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x_binary
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">TernaryQuantization</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;三值量化：+1/0/-1&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, threshold<span style="color:#f92672">=</span><span style="color:#ae81ff">0.7</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>threshold <span style="color:#f92672">=</span> threshold
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 计算阈值</span>
</span></span><span style="display:flex;"><span>        x_abs <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>abs(x)
</span></span><span style="display:flex;"><span>        threshold <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>threshold <span style="color:#f92672">*</span> x_abs<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 三值量化</span>
</span></span><span style="display:flex;"><span>        x_ternary <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>sign(x)
</span></span><span style="display:flex;"><span>        x_ternary[x_abs <span style="color:#f92672">&lt;</span> threshold] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 缩放因子（保持方差）</span>
</span></span><span style="display:flex;"><span>        scale <span style="color:#f92672">=</span> x_abs[x_abs <span style="color:#f92672">&gt;=</span> threshold]<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>        x_ternary <span style="color:#f92672">=</span> x_ternary <span style="color:#f92672">*</span> scale
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># STE</span>
</span></span><span style="display:flex;"><span>        x_ternary <span style="color:#f92672">=</span> x <span style="color:#f92672">+</span> (x_ternary <span style="color:#f92672">-</span> x)<span style="color:#f92672">.</span>detach()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x_ternary
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">XNORNet</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;XNOR-Net: 二值神经网络&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>features <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            BinaryConv2d(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">64</span>),
</span></span><span style="display:flex;"><span>            BinaryActivation(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            BinaryConv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">128</span>),
</span></span><span style="display:flex;"><span>            BinaryActivation(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>features(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">BinaryConv2d</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;二值卷积层&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, in_channels, out_channels, kernel_size, <span style="color:#f92672">**</span>kwargs):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(in_channels, out_channels, kernel_size, <span style="color:#f92672">**</span>kwargs)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 二值化权重</span>
</span></span><span style="display:flex;"><span>        w <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>weight
</span></span><span style="display:flex;"><span>        w_binary <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>sign(w)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 计算缩放因子</span>
</span></span><span style="display:flex;"><span>        alpha <span style="color:#f92672">=</span> w<span style="color:#f92672">.</span>abs()<span style="color:#f92672">.</span>mean(dim<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">3</span>), keepdim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 二值卷积</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> w <span style="color:#f92672">+</span> (w_binary <span style="color:#f92672">-</span> w)<span style="color:#f92672">.</span>detach()
</span></span><span style="display:flex;"><span>        output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv(x)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> w
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> output <span style="color:#f92672">*</span> alpha<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>)
</span></span></code></pre></div><hr>
<h2 id="7-量化调试与优化">7. 量化调试与优化</h2>
<h3 id="71-量化敏感度分析">7.1 量化敏感度分析</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">QuantizationSensitivityAnalyzer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model, calibration_loader, validation_loader):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>calibration_loader <span style="color:#f92672">=</span> calibration_loader
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>validation_loader <span style="color:#f92672">=</span> validation_loader
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">analyze_layer_sensitivity</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;分析每层对量化的敏感度&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 获取原始模型精度</span>
</span></span><span style="display:flex;"><span>        baseline_accuracy <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>evaluate_model(self<span style="color:#f92672">.</span>model)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Baseline accuracy: </span><span style="color:#e6db74">{</span>baseline_accuracy<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">%&#34;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        sensitivity_results <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 遍历每一层</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(module, (nn<span style="color:#f92672">.</span>Conv2d, nn<span style="color:#f92672">.</span>Linear)):
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Analyzing layer: </span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 保存原始权重</span>
</span></span><span style="display:flex;"><span>                original_weight <span style="color:#f92672">=</span> module<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>clone()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 测试不同量化位数</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> num_bits <span style="color:#f92672">in</span> [<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">2</span>]:
</span></span><span style="display:flex;"><span>                    <span style="color:#75715e"># 量化该层</span>
</span></span><span style="display:flex;"><span>                    quantized_weight <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quantize_tensor(
</span></span><span style="display:flex;"><span>                        original_weight, num_bits
</span></span><span style="display:flex;"><span>                    )
</span></span><span style="display:flex;"><span>                    module<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> quantized_weight
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>                    <span style="color:#75715e"># 评估精度</span>
</span></span><span style="display:flex;"><span>                    accuracy <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>evaluate_model(self<span style="color:#f92672">.</span>model)
</span></span><span style="display:flex;"><span>                    drop <span style="color:#f92672">=</span> baseline_accuracy <span style="color:#f92672">-</span> accuracy
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">if</span> name <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> sensitivity_results:
</span></span><span style="display:flex;"><span>                        sensitivity_results[name] <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>                    sensitivity_results[name][<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>num_bits<span style="color:#e6db74">}</span><span style="color:#e6db74">bit&#39;</span>] <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>                        <span style="color:#e6db74">&#39;accuracy&#39;</span>: accuracy,
</span></span><span style="display:flex;"><span>                        <span style="color:#e6db74">&#39;drop&#39;</span>: drop
</span></span><span style="display:flex;"><span>                    }
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>                    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  </span><span style="color:#e6db74">{</span>num_bits<span style="color:#e6db74">}</span><span style="color:#e6db74">-bit: </span><span style="color:#e6db74">{</span>accuracy<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">% (drop: </span><span style="color:#e6db74">{</span>drop<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">%)&#34;</span>)
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 恢复原始权重</span>
</span></span><span style="display:flex;"><span>                module<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> original_weight
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> sensitivity_results
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">quantize_tensor</span>(self, tensor, num_bits):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;量化张量&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> num_bits <span style="color:#f92672">==</span> <span style="color:#ae81ff">32</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> tensor
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 计算量化参数</span>
</span></span><span style="display:flex;"><span>        min_val <span style="color:#f92672">=</span> tensor<span style="color:#f92672">.</span>min()
</span></span><span style="display:flex;"><span>        max_val <span style="color:#f92672">=</span> tensor<span style="color:#f92672">.</span>max()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        qmin <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>(<span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>(num_bits<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        qmax <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>(num_bits<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        scale <span style="color:#f92672">=</span> (max_val <span style="color:#f92672">-</span> min_val) <span style="color:#f92672">/</span> (qmax <span style="color:#f92672">-</span> qmin)
</span></span><span style="display:flex;"><span>        zero_point <span style="color:#f92672">=</span> qmin <span style="color:#f92672">-</span> torch<span style="color:#f92672">.</span>round(min_val <span style="color:#f92672">/</span> scale)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 量化和反量化</span>
</span></span><span style="display:flex;"><span>        tensor_q <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>round(tensor <span style="color:#f92672">/</span> scale <span style="color:#f92672">+</span> zero_point)
</span></span><span style="display:flex;"><span>        tensor_q <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>clamp(tensor_q, qmin, qmax)
</span></span><span style="display:flex;"><span>        tensor_deq <span style="color:#f92672">=</span> scale <span style="color:#f92672">*</span> (tensor_q <span style="color:#f92672">-</span> zero_point)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> tensor_deq
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">find_optimal_bit_allocation</span>(self, target_model_bits):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;找到最优的位分配方案&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        sensitivity <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>analyze_layer_sensitivity()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 根据敏感度排序层</span>
</span></span><span style="display:flex;"><span>        layer_importance <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> layer_name, results <span style="color:#f92672">in</span> sensitivity<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 计算敏感度分数（8bit到4bit的精度下降）</span>
</span></span><span style="display:flex;"><span>            sensitivity_score <span style="color:#f92672">=</span> results[<span style="color:#e6db74">&#39;4bit&#39;</span>][<span style="color:#e6db74">&#39;drop&#39;</span>] <span style="color:#f92672">-</span> results[<span style="color:#e6db74">&#39;8bit&#39;</span>][<span style="color:#e6db74">&#39;drop&#39;</span>]
</span></span><span style="display:flex;"><span>            layer_importance<span style="color:#f92672">.</span>append((layer_name, sensitivity_score))
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        layer_importance<span style="color:#f92672">.</span>sort(key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x: x[<span style="color:#ae81ff">1</span>], reverse<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 分配位数：重要的层用更多位</span>
</span></span><span style="display:flex;"><span>        bit_allocation <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i, (layer_name, _) <span style="color:#f92672">in</span> enumerate(layer_importance):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> i <span style="color:#f92672">&lt;</span> len(layer_importance) <span style="color:#f92672">//</span> <span style="color:#ae81ff">3</span>:
</span></span><span style="display:flex;"><span>                bit_allocation[layer_name] <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>  <span style="color:#75715e"># 最重要的1/3用8位</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">elif</span> i <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> len(layer_importance) <span style="color:#f92672">//</span> <span style="color:#ae81ff">3</span>:
</span></span><span style="display:flex;"><span>                bit_allocation[layer_name] <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span>  <span style="color:#75715e"># 中间1/3用6位</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                bit_allocation[layer_name] <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>  <span style="color:#75715e"># 最不重要的1/3用4位</span>
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> bit_allocation
</span></span></code></pre></div><h3 id="72-量化错误分析">7.2 量化错误分析</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">QuantizationErrorAnalyzer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, float_model, quantized_model):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>float_model <span style="color:#f92672">=</span> float_model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>quantized_model <span style="color:#f92672">=</span> quantized_model
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">analyze_activation_errors</span>(self, input_data):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;分析激活值的量化误差&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>float_model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>quantized_model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        float_activations <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>        quantized_activations <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 注册钩子收集激活值</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_activation</span>(name, activation_dict):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">hook</span>(model, input, output):
</span></span><span style="display:flex;"><span>                activation_dict[name] <span style="color:#f92672">=</span> output<span style="color:#f92672">.</span>detach()
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> hook
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 为每层注册钩子</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>float_model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(module, (nn<span style="color:#f92672">.</span>Conv2d, nn<span style="color:#f92672">.</span>Linear, nn<span style="color:#f92672">.</span>ReLU)):
</span></span><span style="display:flex;"><span>                module<span style="color:#f92672">.</span>register_forward_hook(
</span></span><span style="display:flex;"><span>                    get_activation(name, float_activations)
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>quantized_model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(module, (nn<span style="color:#f92672">.</span>Conv2d, nn<span style="color:#f92672">.</span>Linear, nn<span style="color:#f92672">.</span>ReLU)):
</span></span><span style="display:flex;"><span>                module<span style="color:#f92672">.</span>register_forward_hook(
</span></span><span style="display:flex;"><span>                    get_activation(name, quantized_activations)
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 前向传播</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>float_model(input_data)
</span></span><span style="display:flex;"><span>            _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quantized_model(input_data)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 分析误差</span>
</span></span><span style="display:flex;"><span>        error_stats <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name <span style="color:#f92672">in</span> float_activations:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> name <span style="color:#f92672">in</span> quantized_activations:
</span></span><span style="display:flex;"><span>                float_act <span style="color:#f92672">=</span> float_activations[name]
</span></span><span style="display:flex;"><span>                quant_act <span style="color:#f92672">=</span> quantized_activations[name]
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 计算各种误差指标</span>
</span></span><span style="display:flex;"><span>                mse <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mean((float_act <span style="color:#f92672">-</span> quant_act) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>                mae <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mean(torch<span style="color:#f92672">.</span>abs(float_act <span style="color:#f92672">-</span> quant_act))<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 相对误差</span>
</span></span><span style="display:flex;"><span>                rel_error <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mean(
</span></span><span style="display:flex;"><span>                    torch<span style="color:#f92672">.</span>abs(float_act <span style="color:#f92672">-</span> quant_act) <span style="color:#f92672">/</span> 
</span></span><span style="display:flex;"><span>                    (torch<span style="color:#f92672">.</span>abs(float_act) <span style="color:#f92672">+</span> <span style="color:#ae81ff">1e-8</span>)
</span></span><span style="display:flex;"><span>                )<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 余弦相似度</span>
</span></span><span style="display:flex;"><span>                cos_sim <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>cosine_similarity(
</span></span><span style="display:flex;"><span>                    float_act<span style="color:#f92672">.</span>flatten(), 
</span></span><span style="display:flex;"><span>                    quant_act<span style="color:#f92672">.</span>flatten(), 
</span></span><span style="display:flex;"><span>                    dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>                )<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                error_stats[name] <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#39;mse&#39;</span>: mse,
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#39;mae&#39;</span>: mae,
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#39;relative_error&#39;</span>: rel_error,
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#39;cosine_similarity&#39;</span>: cos_sim
</span></span><span style="display:flex;"><span>                }
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> error_stats
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">visualize_weight_distributions</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;可视化权重分布的变化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        fig, axes <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">10</span>))
</span></span><span style="display:flex;"><span>        axes <span style="color:#f92672">=</span> axes<span style="color:#f92672">.</span>ravel()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        layer_idx <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>float_model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(module, (nn<span style="color:#f92672">.</span>Conv2d, nn<span style="color:#f92672">.</span>Linear)) <span style="color:#f92672">and</span> layer_idx <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">4</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 获取浮点权重</span>
</span></span><span style="display:flex;"><span>                float_weights <span style="color:#f92672">=</span> module<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>cpu()<span style="color:#f92672">.</span>numpy()<span style="color:#f92672">.</span>flatten()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 获取量化权重</span>
</span></span><span style="display:flex;"><span>                quant_module <span style="color:#f92672">=</span> dict(self<span style="color:#f92672">.</span>quantized_model<span style="color:#f92672">.</span>named_modules())[name]
</span></span><span style="display:flex;"><span>                quant_weights <span style="color:#f92672">=</span> quant_module<span style="color:#f92672">.</span>weight()<span style="color:#f92672">.</span>dequantize()<span style="color:#f92672">.</span>cpu()<span style="color:#f92672">.</span>numpy()<span style="color:#f92672">.</span>flatten()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 绘制分布</span>
</span></span><span style="display:flex;"><span>                ax <span style="color:#f92672">=</span> axes[layer_idx]
</span></span><span style="display:flex;"><span>                ax<span style="color:#f92672">.</span>hist(float_weights, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Float32&#39;</span>, density<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>                ax<span style="color:#f92672">.</span>hist(quant_weights, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;INT8&#39;</span>, density<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>                ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Layer: </span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>                ax<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;Weight Value&#39;</span>)
</span></span><span style="display:flex;"><span>                ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;Density&#39;</span>)
</span></span><span style="display:flex;"><span>                ax<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                layer_idx <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        plt<span style="color:#f92672">.</span>tight_layout()
</span></span><span style="display:flex;"><span>        plt<span style="color:#f92672">.</span>savefig(<span style="color:#e6db74">&#39;weight_distribution_comparison.png&#39;</span>)
</span></span><span style="display:flex;"><span>        plt<span style="color:#f92672">.</span>close()
</span></span></code></pre></div><h3 id="73-量化模型优化">7.3 量化模型优化</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">QuantizationOptimizer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model, calibration_data):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>calibration_data <span style="color:#f92672">=</span> calibration_data
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">optimize_quantization_parameters</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;优化量化参数以最小化误差&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        optimized_params <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> hasattr(module, <span style="color:#e6db74">&#39;observer&#39;</span>):
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Optimizing </span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 收集激活值</span>
</span></span><span style="display:flex;"><span>                activations <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">hook</span>(module, input, output):
</span></span><span style="display:flex;"><span>                    activations<span style="color:#f92672">.</span>append(output<span style="color:#f92672">.</span>detach())
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>                handle <span style="color:#f92672">=</span> module<span style="color:#f92672">.</span>register_forward_hook(hook)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 运行校准数据</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">for</span> data <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>calibration_data:
</span></span><span style="display:flex;"><span>                        _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model(data)
</span></span><span style="display:flex;"><span>                        
</span></span><span style="display:flex;"><span>                handle<span style="color:#f92672">.</span>remove()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 优化量化参数</span>
</span></span><span style="display:flex;"><span>                all_activations <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat(activations)
</span></span><span style="display:flex;"><span>                optimal_scale, optimal_zero_point <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>optimize_scale_zp(
</span></span><span style="display:flex;"><span>                    all_activations
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                optimized_params[name] <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#39;scale&#39;</span>: optimal_scale,
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#39;zero_point&#39;</span>: optimal_zero_point
</span></span><span style="display:flex;"><span>                }
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> optimized_params
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">optimize_scale_zp</span>(self, tensor, num_bits<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;使用网格搜索优化scale和zero_point&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        min_val <span style="color:#f92672">=</span> tensor<span style="color:#f92672">.</span>min()<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>        max_val <span style="color:#f92672">=</span> tensor<span style="color:#f92672">.</span>max()<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        best_scale <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>        best_zero_point <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>        min_error <span style="color:#f92672">=</span> float(<span style="color:#e6db74">&#39;inf&#39;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 网格搜索</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> scale_factor <span style="color:#f92672">in</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">1.2</span>, <span style="color:#ae81ff">20</span>):
</span></span><span style="display:flex;"><span>            test_scale <span style="color:#f92672">=</span> (max_val <span style="color:#f92672">-</span> min_val) <span style="color:#f92672">/</span> (<span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>num_bits <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>) <span style="color:#f92672">*</span> scale_factor
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> zp_offset <span style="color:#f92672">in</span> range(<span style="color:#f92672">-</span><span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">11</span>):
</span></span><span style="display:flex;"><span>                test_zp <span style="color:#f92672">=</span> round(<span style="color:#f92672">-</span>min_val <span style="color:#f92672">/</span> test_scale) <span style="color:#f92672">+</span> zp_offset
</span></span><span style="display:flex;"><span>                test_zp <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>clip(test_zp, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>num_bits <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 量化和反量化</span>
</span></span><span style="display:flex;"><span>                tensor_q <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>round(tensor <span style="color:#f92672">/</span> test_scale <span style="color:#f92672">+</span> test_zp)
</span></span><span style="display:flex;"><span>                tensor_q <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>clamp(tensor_q, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span><span style="color:#f92672">**</span>num_bits <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>                tensor_dq <span style="color:#f92672">=</span> (tensor_q <span style="color:#f92672">-</span> test_zp) <span style="color:#f92672">*</span> test_scale
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 计算误差</span>
</span></span><span style="display:flex;"><span>                error <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>mean((tensor <span style="color:#f92672">-</span> tensor_dq) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> error <span style="color:#f92672">&lt;</span> min_error:
</span></span><span style="display:flex;"><span>                    min_error <span style="color:#f92672">=</span> error
</span></span><span style="display:flex;"><span>                    best_scale <span style="color:#f92672">=</span> test_scale
</span></span><span style="display:flex;"><span>                    best_zero_point <span style="color:#f92672">=</span> test_zp
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> best_scale, best_zero_point
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">apply_graph_optimization</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;应用计算图优化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 1. 算子融合</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>fuse_modules(self<span style="color:#f92672">.</span>model, [
</span></span><span style="display:flex;"><span>            [<span style="color:#e6db74">&#39;conv1&#39;</span>, <span style="color:#e6db74">&#39;bn1&#39;</span>, <span style="color:#e6db74">&#39;relu1&#39;</span>],
</span></span><span style="display:flex;"><span>            [<span style="color:#e6db74">&#39;conv2&#39;</span>, <span style="color:#e6db74">&#39;bn2&#39;</span>, <span style="color:#e6db74">&#39;relu2&#39;</span>],
</span></span><span style="display:flex;"><span>        ])
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 2. 常量折叠</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>script(self<span style="color:#f92672">.</span>model)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>optimize_for_inference(self<span style="color:#f92672">.</span>model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>model
</span></span></code></pre></div><hr>
<h2 id="9-实际案例分析">9. 实际案例分析</h2>
<h3 id="91-bert模型量化案例">9.1 BERT模型量化案例</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> BertModel, BertTokenizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.quantization <span style="color:#66d9ef">as</span> tq
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">BERTQuantizationCase</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;bert-base-uncased&#39;</span>):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>tokenizer <span style="color:#f92672">=</span> BertTokenizer<span style="color:#f92672">.</span>from_pretrained(model_name)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> BertModel<span style="color:#f92672">.</span>from_pretrained(model_name)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">prepare_bert_for_quantization</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;准备BERT模型进行量化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># BERT特殊处理：某些层不适合量化</span>
</span></span><span style="display:flex;"><span>        quantization_blacklist <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;embeddings&#39;</span>,  <span style="color:#75715e"># 嵌入层保持高精度</span>
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;pooler&#39;</span>,      <span style="color:#75715e"># 池化层</span>
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 设置量化配置</span>
</span></span><span style="display:flex;"><span>        qconfig <span style="color:#f92672">=</span> tq<span style="color:#f92672">.</span>QConfig(
</span></span><span style="display:flex;"><span>            activation<span style="color:#f92672">=</span>tq<span style="color:#f92672">.</span>HistogramObserver<span style="color:#f92672">.</span>with_args(
</span></span><span style="display:flex;"><span>                quant_min<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, 
</span></span><span style="display:flex;"><span>                quant_max<span style="color:#f92672">=</span><span style="color:#ae81ff">127</span>,
</span></span><span style="display:flex;"><span>                dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>quint8,
</span></span><span style="display:flex;"><span>                reduce_range<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>  <span style="color:#75715e"># 对激活值使用reduced range</span>
</span></span><span style="display:flex;"><span>            ),
</span></span><span style="display:flex;"><span>            weight<span style="color:#f92672">=</span>tq<span style="color:#f92672">.</span>PerChannelMinMaxObserver<span style="color:#f92672">.</span>with_args(
</span></span><span style="display:flex;"><span>                dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>qint8,
</span></span><span style="display:flex;"><span>                qscheme<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>per_channel_symmetric
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 应用量化配置</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 检查是否在黑名单中</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> any(blacklist_item <span style="color:#f92672">in</span> name <span style="color:#66d9ef">for</span> blacklist_item <span style="color:#f92672">in</span> quantization_blacklist):
</span></span><span style="display:flex;"><span>                module<span style="color:#f92672">.</span>qconfig <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                module<span style="color:#f92672">.</span>qconfig <span style="color:#f92672">=</span> qconfig
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">quantize_bert_dynamic</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;BERT动态量化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 动态量化对BERT效果较好</span>
</span></span><span style="display:flex;"><span>        quantized_model <span style="color:#f92672">=</span> tq<span style="color:#f92672">.</span>quantize_dynamic(
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>model,
</span></span><span style="display:flex;"><span>            {
</span></span><span style="display:flex;"><span>                torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear: tq<span style="color:#f92672">.</span>default_dynamic_qconfig,
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># BERT使用的是nn.Linear而不是单独的LSTM/GRU</span>
</span></span><span style="display:flex;"><span>            },
</span></span><span style="display:flex;"><span>            dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>qint8
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> quantized_model
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">quantize_bert_static</span>(self, calibration_data):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;BERT静态量化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 准备模型</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>prepare_bert_for_quantization()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 准备量化</span>
</span></span><span style="display:flex;"><span>        prepared_model <span style="color:#f92672">=</span> tq<span style="color:#f92672">.</span>prepare(self<span style="color:#f92672">.</span>model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 校准</span>
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;Calibrating BERT...&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> batch <span style="color:#f92672">in</span> calibration_data:
</span></span><span style="display:flex;"><span>                input_ids <span style="color:#f92672">=</span> batch[<span style="color:#e6db74">&#39;input_ids&#39;</span>]
</span></span><span style="display:flex;"><span>                attention_mask <span style="color:#f92672">=</span> batch[<span style="color:#e6db74">&#39;attention_mask&#39;</span>]
</span></span><span style="display:flex;"><span>                _ <span style="color:#f92672">=</span> prepared_model(input_ids, attention_mask<span style="color:#f92672">=</span>attention_mask)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 转换</span>
</span></span><span style="display:flex;"><span>        quantized_model <span style="color:#f92672">=</span> tq<span style="color:#f92672">.</span>convert(prepared_model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> quantized_model
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compare_inference_speed</span>(self, test_sentences, num_runs<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;比较推理速度&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 准备输入</span>
</span></span><span style="display:flex;"><span>        inputs <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>tokenizer(
</span></span><span style="display:flex;"><span>            test_sentences, 
</span></span><span style="display:flex;"><span>            padding<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, 
</span></span><span style="display:flex;"><span>            truncation<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, 
</span></span><span style="display:flex;"><span>            return_tensors<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;pt&#39;</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 原始模型</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        start <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(num_runs):
</span></span><span style="display:flex;"><span>                _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model(<span style="color:#f92672">**</span>inputs)
</span></span><span style="display:flex;"><span>        original_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> start
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 量化模型</span>
</span></span><span style="display:flex;"><span>        quantized_model <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quantize_bert_dynamic()
</span></span><span style="display:flex;"><span>        start <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(num_runs):
</span></span><span style="display:flex;"><span>                _ <span style="color:#f92672">=</span> quantized_model(<span style="color:#f92672">**</span>inputs)
</span></span><span style="display:flex;"><span>        quantized_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> start
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Original model: </span><span style="color:#e6db74">{</span>original_time<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">s&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Quantized model: </span><span style="color:#e6db74">{</span>quantized_time<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">s&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Speedup: </span><span style="color:#e6db74">{</span>original_time<span style="color:#f92672">/</span>quantized_time<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">x&#34;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">measure_model_size</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;测量模型大小&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 保存原始模型</span>
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>save(self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>state_dict(), <span style="color:#e6db74">&#39;bert_original.pth&#39;</span>)
</span></span><span style="display:flex;"><span>        original_size <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>getsize(<span style="color:#e6db74">&#39;bert_original.pth&#39;</span>) <span style="color:#f92672">/</span> <span style="color:#ae81ff">1024</span> <span style="color:#f92672">/</span> <span style="color:#ae81ff">1024</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 保存量化模型</span>
</span></span><span style="display:flex;"><span>        quantized_model <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quantize_bert_dynamic()
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>save(quantized_model<span style="color:#f92672">.</span>state_dict(), <span style="color:#e6db74">&#39;bert_quantized.pth&#39;</span>)
</span></span><span style="display:flex;"><span>        quantized_size <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>getsize(<span style="color:#e6db74">&#39;bert_quantized.pth&#39;</span>) <span style="color:#f92672">/</span> <span style="color:#ae81ff">1024</span> <span style="color:#f92672">/</span> <span style="color:#ae81ff">1024</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Original model size: </span><span style="color:#e6db74">{</span>original_size<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> MB&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Quantized model size: </span><span style="color:#e6db74">{</span>quantized_size<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> MB&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Compression ratio: </span><span style="color:#e6db74">{</span>original_size<span style="color:#f92672">/</span>quantized_size<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">x&#34;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 清理</span>
</span></span><span style="display:flex;"><span>        os<span style="color:#f92672">.</span>remove(<span style="color:#e6db74">&#39;bert_original.pth&#39;</span>)
</span></span><span style="display:flex;"><span>        os<span style="color:#f92672">.</span>remove(<span style="color:#e6db74">&#39;bert_quantized.pth&#39;</span>)
</span></span></code></pre></div><h3 id="92-resnet量化案例">9.2 ResNet量化案例</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ResNetQuantizationCase</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>resnet50(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">prepare_resnet_for_mobile</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;为移动端部署准备ResNet&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 1. 模型修改：去除不必要的层</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MobileResNet</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">def</span> __init__(self, original_model):
</span></span><span style="display:flex;"><span>                super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 复制除了最后的FC层</span>
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>features <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">*</span>list(original_model<span style="color:#f92672">.</span>children())[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 添加量化/反量化节点</span>
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>quant <span style="color:#f92672">=</span> tq<span style="color:#f92672">.</span>QuantStub()
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>dequant <span style="color:#f92672">=</span> tq<span style="color:#f92672">.</span>DeQuantStub()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 新的轻量级分类头</span>
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>classifier <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Dropout(<span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>                    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">2048</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quant(x)
</span></span><span style="display:flex;"><span>                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>features(x)
</span></span><span style="display:flex;"><span>                x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>flatten(x, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>classifier(x)
</span></span><span style="display:flex;"><span>                x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dequant(x)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        mobile_model <span style="color:#f92672">=</span> MobileResNet(self<span style="color:#f92672">.</span>model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 2. 融合BatchNorm</span>
</span></span><span style="display:flex;"><span>        mobile_model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        mobile_model <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_fuse_resnet_modules(mobile_model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> mobile_model
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_fuse_resnet_modules</span>(self, model):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;融合ResNet中的模块&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># ResNet的特殊结构需要仔细处理</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> module_name, module <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>named_children():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> module_name <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;features&#39;</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> idx, layer <span style="color:#f92672">in</span> enumerate(module):
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">if</span> hasattr(layer, <span style="color:#e6db74">&#39;conv1&#39;</span>):
</span></span><span style="display:flex;"><span>                        <span style="color:#75715e"># 基本块</span>
</span></span><span style="display:flex;"><span>                        torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>fuse_modules(layer, [
</span></span><span style="display:flex;"><span>                            [<span style="color:#e6db74">&#39;conv1&#39;</span>, <span style="color:#e6db74">&#39;bn1&#39;</span>],
</span></span><span style="display:flex;"><span>                            [<span style="color:#e6db74">&#39;conv2&#39;</span>, <span style="color:#e6db74">&#39;bn2&#39;</span>]
</span></span><span style="display:flex;"><span>                        ], inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>                        
</span></span><span style="display:flex;"><span>                        <span style="color:#75715e"># 如果有conv3（瓶颈块）</span>
</span></span><span style="display:flex;"><span>                        <span style="color:#66d9ef">if</span> hasattr(layer, <span style="color:#e6db74">&#39;conv3&#39;</span>):
</span></span><span style="display:flex;"><span>                            torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>fuse_modules(layer, [
</span></span><span style="display:flex;"><span>                                [<span style="color:#e6db74">&#39;conv3&#39;</span>, <span style="color:#e6db74">&#39;bn3&#39;</span>]
</span></span><span style="display:flex;"><span>                            ], inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>                            
</span></span><span style="display:flex;"><span>                        <span style="color:#75715e"># 下采样</span>
</span></span><span style="display:flex;"><span>                        <span style="color:#66d9ef">if</span> hasattr(layer, <span style="color:#e6db74">&#39;downsample&#39;</span>):
</span></span><span style="display:flex;"><span>                            torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>fuse_modules(
</span></span><span style="display:flex;"><span>                                layer<span style="color:#f92672">.</span>downsample, 
</span></span><span style="display:flex;"><span>                                [<span style="color:#e6db74">&#39;0&#39;</span>, <span style="color:#e6db74">&#39;1&#39;</span>],  <span style="color:#75715e"># conv, bn</span>
</span></span><span style="display:flex;"><span>                                inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>                            )
</span></span><span style="display:flex;"><span>                            
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> model
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">quantize_with_qat</span>(self, train_loader, val_loader, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;使用QAT量化ResNet&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 准备模型</span>
</span></span><span style="display:flex;"><span>        model <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>prepare_resnet_for_mobile()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># QAT配置</span>
</span></span><span style="display:flex;"><span>        model<span style="color:#f92672">.</span>qconfig <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>get_default_qat_qconfig(<span style="color:#e6db74">&#39;fbgemm&#39;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 准备QAT</span>
</span></span><span style="display:flex;"><span>        model<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>        model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>prepare_qat(model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 训练</span>
</span></span><span style="display:flex;"><span>        optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>SGD(model<span style="color:#f92672">.</span>parameters(), lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.9</span>)
</span></span><span style="display:flex;"><span>        criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epochs):
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 训练阶段</span>
</span></span><span style="display:flex;"><span>            model<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> batch_idx, (data, target) <span style="color:#f92672">in</span> enumerate(train_loader):
</span></span><span style="display:flex;"><span>                optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>                output <span style="color:#f92672">=</span> model(data)
</span></span><span style="display:flex;"><span>                loss <span style="color:#f92672">=</span> criterion(output, target)
</span></span><span style="display:flex;"><span>                loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>                optimizer<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> batch_idx <span style="color:#f92672">%</span> <span style="color:#ae81ff">100</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>                    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Epoch </span><span style="color:#e6db74">{</span>epoch<span style="color:#e6db74">}</span><span style="color:#e6db74">, Batch </span><span style="color:#e6db74">{</span>batch_idx<span style="color:#e6db74">}</span><span style="color:#e6db74">, Loss: </span><span style="color:#e6db74">{</span>loss<span style="color:#f92672">.</span>item()<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 验证阶段</span>
</span></span><span style="display:flex;"><span>            model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>            correct <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> data, target <span style="color:#f92672">in</span> val_loader:
</span></span><span style="display:flex;"><span>                    output <span style="color:#f92672">=</span> model(data)
</span></span><span style="display:flex;"><span>                    pred <span style="color:#f92672">=</span> output<span style="color:#f92672">.</span>argmax(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>                    correct <span style="color:#f92672">+=</span> pred<span style="color:#f92672">.</span>eq(target)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>                    
</span></span><span style="display:flex;"><span>            accuracy <span style="color:#f92672">=</span> <span style="color:#ae81ff">100.</span> <span style="color:#f92672">*</span> correct <span style="color:#f92672">/</span> len(val_loader<span style="color:#f92672">.</span>dataset)
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Epoch </span><span style="color:#e6db74">{</span>epoch<span style="color:#e6db74">}</span><span style="color:#e6db74">, Validation Accuracy: </span><span style="color:#e6db74">{</span>accuracy<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">%&#39;</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 转换为量化模型</span>
</span></span><span style="display:flex;"><span>        model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        quantized_model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>convert(model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> quantized_model
</span></span></code></pre></div><h3 id="93-yolo目标检测量化案例">9.3 YOLO目标检测量化案例</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">YOLOQuantizationCase</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model_path):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>load_yolo_model(model_path)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">quantize_yolo_preserving_accuracy</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;保持精度的YOLO量化策略&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># YOLO特殊考虑：</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 1. 检测头需要高精度</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 2. 特征提取可以更激进地量化</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 混合精度配置</span>
</span></span><span style="display:flex;"><span>        mixed_precision_config <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Backbone - 可以使用更低精度</span>
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;backbone.conv1&#39;</span>: <span style="color:#ae81ff">4</span>,  <span style="color:#75715e"># 4-bit</span>
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;backbone.conv2&#39;</span>: <span style="color:#ae81ff">4</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;backbone.conv3&#39;</span>: <span style="color:#ae81ff">6</span>,  <span style="color:#75715e"># 6-bit</span>
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;backbone.conv4&#39;</span>: <span style="color:#ae81ff">6</span>,
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Neck - 中等精度</span>
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;neck.conv1&#39;</span>: <span style="color:#ae81ff">8</span>,  <span style="color:#75715e"># 8-bit</span>
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;neck.conv2&#39;</span>: <span style="color:#ae81ff">8</span>,
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Head - 保持高精度</span>
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;head.detect1&#39;</span>: <span style="color:#ae81ff">16</span>,  <span style="color:#75715e"># FP16</span>
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;head.detect2&#39;</span>: <span style="color:#ae81ff">16</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;head.detect3&#39;</span>: <span style="color:#ae81ff">16</span>,
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 应用混合精度量化</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> name <span style="color:#f92672">in</span> mixed_precision_config:
</span></span><span style="display:flex;"><span>                bits <span style="color:#f92672">=</span> mixed_precision_config[name]
</span></span><span style="display:flex;"><span>                module<span style="color:#f92672">.</span>qconfig <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_get_qconfig_for_bits(bits)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">elif</span> <span style="color:#e6db74">&#39;backbone&#39;</span> <span style="color:#f92672">in</span> name:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 默认backbone使用INT4</span>
</span></span><span style="display:flex;"><span>                module<span style="color:#f92672">.</span>qconfig <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_get_qconfig_for_bits(<span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 其他部分使用INT8</span>
</span></span><span style="display:flex;"><span>                module<span style="color:#f92672">.</span>qconfig <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>default_qconfig
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">post_process_quantized_outputs</span>(self, outputs):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;后处理量化输出&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># YOLO输出包含：位置、置信度、类别概率</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 需要特殊处理以保持检测精度</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        boxes <span style="color:#f92672">=</span> outputs[<span style="color:#f92672">...</span>, :<span style="color:#ae81ff">4</span>]  <span style="color:#75715e"># 边界框</span>
</span></span><span style="display:flex;"><span>        confidence <span style="color:#f92672">=</span> outputs[<span style="color:#f92672">...</span>, <span style="color:#ae81ff">4</span>:<span style="color:#ae81ff">5</span>]  <span style="color:#75715e"># 置信度</span>
</span></span><span style="display:flex;"><span>        class_probs <span style="color:#f92672">=</span> outputs[<span style="color:#f92672">...</span>, <span style="color:#ae81ff">5</span>:]  <span style="color:#75715e"># 类别概率</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 对边界框进行额外的校准</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 量化可能导致边界框偏移</span>
</span></span><span style="display:flex;"><span>        boxes <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>calibrate_boxes(boxes)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 对置信度使用更严格的阈值</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 量化可能导致更多的假阳性</span>
</span></span><span style="display:flex;"><span>        confidence_threshold <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.5</span>  <span style="color:#75715e"># 比正常阈值略高</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> boxes, confidence, class_probs
</span></span></code></pre></div><hr>
<h2 id="10-常见问题与解决方案">10. 常见问题与解决方案</h2>
<h3 id="101-量化后精度严重下降">10.1 量化后精度严重下降</h3>
<p><strong>问题分析：</strong></p>
<ol>
<li>某些层对量化特别敏感</li>
<li>激活值分布有长尾</li>
<li>量化参数选择不当</li>
</ol>
<p><strong>解决方案：</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">AccuracyRecoveryTechniques</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, float_model, quantized_model):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>float_model <span style="color:#f92672">=</span> float_model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>quantized_model <span style="color:#f92672">=</span> quantized_model
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">selective_quantization</span>(self, sensitive_layers):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;选择性量化：跳过敏感层&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>quantized_model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> name <span style="color:#f92672">in</span> sensitive_layers:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 恢复为浮点</span>
</span></span><span style="display:flex;"><span>                float_module <span style="color:#f92672">=</span> dict(self<span style="color:#f92672">.</span>float_model<span style="color:#f92672">.</span>named_modules())[name]
</span></span><span style="display:flex;"><span>                setattr(self<span style="color:#f92672">.</span>quantized_model, name<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;.&#39;</span>)[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>], float_module)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">outlier_suppression</span>(self, activation_data, percentile<span style="color:#f92672">=</span><span style="color:#ae81ff">99.9</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;异常值抑制&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 计算激活值的百分位数</span>
</span></span><span style="display:flex;"><span>        lower <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantile(activation_data, (<span style="color:#ae81ff">100</span> <span style="color:#f92672">-</span> percentile) <span style="color:#f92672">/</span> <span style="color:#ae81ff">100</span>)
</span></span><span style="display:flex;"><span>        upper <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantile(activation_data, percentile <span style="color:#f92672">/</span> <span style="color:#ae81ff">100</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 裁剪异常值</span>
</span></span><span style="display:flex;"><span>        clipped_data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>clamp(activation_data, lower, upper)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> clipped_data
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">knowledge_distillation_finetune</span>(self, train_loader, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;使用知识蒸馏微调量化模型&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(self<span style="color:#f92672">.</span>quantized_model<span style="color:#f92672">.</span>parameters(), lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>)
</span></span><span style="display:flex;"><span>        kl_div <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>KLDivLoss(reduction<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;batchmean&#39;</span>)
</span></span><span style="display:flex;"><span>        ce_loss <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>float_model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epochs):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> data, target <span style="color:#f92672">in</span> train_loader:
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>quantized_model<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>                optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 获取教师和学生输出</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>                    teacher_output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>float_model(data)
</span></span><span style="display:flex;"><span>                student_output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quantized_model(data)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 计算损失</span>
</span></span><span style="display:flex;"><span>                T <span style="color:#f92672">=</span> <span style="color:#ae81ff">4.0</span>  <span style="color:#75715e"># 温度参数</span>
</span></span><span style="display:flex;"><span>                distillation_loss <span style="color:#f92672">=</span> kl_div(
</span></span><span style="display:flex;"><span>                    F<span style="color:#f92672">.</span>log_softmax(student_output <span style="color:#f92672">/</span> T, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>                    F<span style="color:#f92672">.</span>softmax(teacher_output <span style="color:#f92672">/</span> T, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>                ) <span style="color:#f92672">*</span> T <span style="color:#f92672">*</span> T
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                student_loss <span style="color:#f92672">=</span> ce_loss(student_output, target)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.9</span> <span style="color:#f92672">*</span> distillation_loss <span style="color:#f92672">+</span> <span style="color:#ae81ff">0.1</span> <span style="color:#f92672">*</span> student_loss
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>                optimizer<span style="color:#f92672">.</span>step()
</span></span></code></pre></div><h3 id="102-量化模型推理速度没有提升">10.2 量化模型推理速度没有提升</h3>
<p><strong>可能原因：</strong></p>
<ol>
<li>硬件不支持INT8加速</li>
<li>模型太小，量化开销大于收益</li>
<li>没有使用优化的推理引擎</li>
</ol>
<p><strong>解决方案：</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">InferenceOptimization</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, quantized_model):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> quantized_model
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">optimize_for_hardware</span>(self, target_hardware<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;cpu&#39;</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;针对特定硬件优化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> target_hardware <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;cpu&#39;</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 使用FBGEMM后端（Intel CPU优化）</span>
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>backends<span style="color:#f92672">.</span>quantized<span style="color:#f92672">.</span>engine <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;fbgemm&#39;</span>
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">elif</span> target_hardware <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;arm&#39;</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 使用QNNPACK后端（ARM优化）</span>
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>backends<span style="color:#f92672">.</span>quantized<span style="color:#f92672">.</span>engine <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;qnnpack&#39;</span>
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># JIT编译优化</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>script(self<span style="color:#f92672">.</span>model)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>optimize_for_inference(self<span style="color:#f92672">.</span>model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">batch_inference_optimization</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;批处理推理优化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 使用TorchScript批处理</span>
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">@torch.jit.script</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">optimized_forward</span>(model, x):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> model(x)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> optimized_forward
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">export_to_optimized_format</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;导出到优化格式&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># ONNX导出</span>
</span></span><span style="display:flex;"><span>        dummy_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>onnx<span style="color:#f92672">.</span>export(
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>model,
</span></span><span style="display:flex;"><span>            dummy_input,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;quantized_model.onnx&#34;</span>,
</span></span><span style="display:flex;"><span>            opset_version<span style="color:#f92672">=</span><span style="color:#ae81ff">13</span>,
</span></span><span style="display:flex;"><span>            do_constant_folding<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>            input_names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;input&#39;</span>],
</span></span><span style="display:flex;"><span>            output_names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;output&#39;</span>],
</span></span><span style="display:flex;"><span>            dynamic_axes<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;input&#39;</span>: {<span style="color:#ae81ff">0</span>: <span style="color:#e6db74">&#39;batch_size&#39;</span>}}
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># TensorRT优化（NVIDIA GPU）</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 需要安装torch2trt</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">from</span> torch2trt <span style="color:#f92672">import</span> torch2trt
</span></span><span style="display:flex;"><span>            model_trt <span style="color:#f92672">=</span> torch2trt(
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>model, 
</span></span><span style="display:flex;"><span>                [dummy_input], 
</span></span><span style="display:flex;"><span>                fp16_mode<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, 
</span></span><span style="display:flex;"><span>                int8_mode<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> model_trt
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">ImportError</span>:
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#34;TensorRT not available&#34;</span>)
</span></span></code></pre></div><h3 id="103-量化参数选择困难">10.3 量化参数选择困难</h3>
<p><strong>自动化量化参数搜索：</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">AutoQuantizationSearch</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model, calibration_loader, validation_loader):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>calibration_loader <span style="color:#f92672">=</span> calibration_loader
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>validation_loader <span style="color:#f92672">=</span> validation_loader
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">grid_search_quantization_params</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;网格搜索最优量化参数&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        param_grid <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;observer&#39;</span>: [
</span></span><span style="display:flex;"><span>                torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>MinMaxObserver,
</span></span><span style="display:flex;"><span>                torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>MovingAverageMinMaxObserver,
</span></span><span style="display:flex;"><span>                torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>HistogramObserver
</span></span><span style="display:flex;"><span>            ],
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;reduce_range&#39;</span>: [<span style="color:#66d9ef">True</span>, <span style="color:#66d9ef">False</span>],
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;symmetric&#39;</span>: [<span style="color:#66d9ef">True</span>, <span style="color:#66d9ef">False</span>],
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;per_channel&#39;</span>: [<span style="color:#66d9ef">True</span>, <span style="color:#66d9ef">False</span>]
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        best_accuracy <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        best_params <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">from</span> itertools <span style="color:#f92672">import</span> product
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 生成所有参数组合</span>
</span></span><span style="display:flex;"><span>        keys <span style="color:#f92672">=</span> param_grid<span style="color:#f92672">.</span>keys()
</span></span><span style="display:flex;"><span>        values <span style="color:#f92672">=</span> param_grid<span style="color:#f92672">.</span>values()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> params <span style="color:#f92672">in</span> product(<span style="color:#f92672">*</span>values):
</span></span><span style="display:flex;"><span>            param_dict <span style="color:#f92672">=</span> dict(zip(keys, params))
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Testing: </span><span style="color:#e6db74">{</span>param_dict<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 创建量化配置</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> param_dict[<span style="color:#e6db74">&#39;per_channel&#39;</span>] <span style="color:#f92672">and</span> param_dict[<span style="color:#e6db74">&#39;symmetric&#39;</span>]:
</span></span><span style="display:flex;"><span>                qscheme <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>per_channel_symmetric
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">elif</span> param_dict[<span style="color:#e6db74">&#39;per_channel&#39;</span>]:
</span></span><span style="display:flex;"><span>                qscheme <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>per_channel_affine
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">elif</span> param_dict[<span style="color:#e6db74">&#39;symmetric&#39;</span>]:
</span></span><span style="display:flex;"><span>                qscheme <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>per_tensor_symmetric
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                qscheme <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>per_tensor_affine
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>            qconfig <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>QConfig(
</span></span><span style="display:flex;"><span>                activation<span style="color:#f92672">=</span>param_dict[<span style="color:#e6db74">&#39;observer&#39;</span>]<span style="color:#f92672">.</span>with_args(
</span></span><span style="display:flex;"><span>                    dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>quint8,
</span></span><span style="display:flex;"><span>                    reduce_range<span style="color:#f92672">=</span>param_dict[<span style="color:#e6db74">&#39;reduce_range&#39;</span>]
</span></span><span style="display:flex;"><span>                ),
</span></span><span style="display:flex;"><span>                weight<span style="color:#f92672">=</span>param_dict[<span style="color:#e6db74">&#39;observer&#39;</span>]<span style="color:#f92672">.</span>with_args(
</span></span><span style="display:flex;"><span>                    dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>qint8,
</span></span><span style="display:flex;"><span>                    qscheme<span style="color:#f92672">=</span>qscheme
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 量化模型</span>
</span></span><span style="display:flex;"><span>            quantized_model <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>quantize_with_config(qconfig)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 评估</span>
</span></span><span style="display:flex;"><span>            accuracy <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>evaluate_model(quantized_model)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> accuracy <span style="color:#f92672">&gt;</span> best_accuracy:
</span></span><span style="display:flex;"><span>                best_accuracy <span style="color:#f92672">=</span> accuracy
</span></span><span style="display:flex;"><span>                best_params <span style="color:#f92672">=</span> param_dict
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Best parameters: </span><span style="color:#e6db74">{</span>best_params<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Best accuracy: </span><span style="color:#e6db74">{</span>best_accuracy<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">%&#34;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> best_params
</span></span></code></pre></div><h3 id="104-部署相关问题">10.4 部署相关问题</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DeploymentSolutions</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, quantized_model):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> quantized_model
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">mobile_deployment_optimization</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;移动端部署优化&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 1. 模型大小优化</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>quantize_dynamic(
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>model,
</span></span><span style="display:flex;"><span>            {nn<span style="color:#f92672">.</span>Linear, nn<span style="color:#f92672">.</span>Conv2d},
</span></span><span style="display:flex;"><span>            dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>qint8
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 2. 转换为TorchScript</span>
</span></span><span style="display:flex;"><span>        example_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)
</span></span><span style="display:flex;"><span>        traced_model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>trace(self<span style="color:#f92672">.</span>model, example_input)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 3. 优化图</span>
</span></span><span style="display:flex;"><span>        optimized_model <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>optimize_for_mobile(traced_model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 4. 保存</span>
</span></span><span style="display:flex;"><span>        optimized_model<span style="color:#f92672">.</span>_save_for_lite_interpreter(<span style="color:#e6db74">&#34;model_mobile.ptl&#34;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> optimized_model
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">edge_device_deployment</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;边缘设备部署&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 转换为ONNX</span>
</span></span><span style="display:flex;"><span>        dummy_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>onnx<span style="color:#f92672">.</span>export(
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>model,
</span></span><span style="display:flex;"><span>            dummy_input,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;model_edge.onnx&#34;</span>,
</span></span><span style="display:flex;"><span>            export_params<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>            opset_version<span style="color:#f92672">=</span><span style="color:#ae81ff">13</span>,
</span></span><span style="display:flex;"><span>            do_constant_folding<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>            input_names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;input&#39;</span>],
</span></span><span style="display:flex;"><span>            output_names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;output&#39;</span>],
</span></span><span style="display:flex;"><span>            dynamic_axes<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;input&#39;</span>: {<span style="color:#ae81ff">0</span>: <span style="color:#e6db74">&#39;batch_size&#39;</span>}},
</span></span><span style="display:flex;"><span>            operator_export_type<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>onnx<span style="color:#f92672">.</span>OperatorExportTypes<span style="color:#f92672">.</span>ONNX_ATEN_FALLBACK
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 使用ONNX Runtime进行INT8推理</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">import</span> onnxruntime <span style="color:#66d9ef">as</span> ort
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 创建INT8推理会话</span>
</span></span><span style="display:flex;"><span>        sess_options <span style="color:#f92672">=</span> ort<span style="color:#f92672">.</span>SessionOptions()
</span></span><span style="display:flex;"><span>        sess_options<span style="color:#f92672">.</span>graph_optimization_level <span style="color:#f92672">=</span> ort<span style="color:#f92672">.</span>GraphOptimizationLevel<span style="color:#f92672">.</span>ORT_ENABLE_ALL
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        session <span style="color:#f92672">=</span> ort<span style="color:#f92672">.</span>InferenceSession(<span style="color:#e6db74">&#34;model_edge.onnx&#34;</span>, sess_options)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> session
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">handle_unsupported_ops</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;处理不支持的操作&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 自定义量化操作</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomQuantizedOp</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">def</span> __init__(self, float_op):
</span></span><span style="display:flex;"><span>                super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>scale <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span>
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>zero_point <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>                self<span style="color:#f92672">.</span>float_op <span style="color:#f92672">=</span> float_op
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 反量化</span>
</span></span><span style="display:flex;"><span>                x_float <span style="color:#f92672">=</span> (x<span style="color:#f92672">.</span>float() <span style="color:#f92672">-</span> self<span style="color:#f92672">.</span>zero_point) <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>scale
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 执行浮点操作</span>
</span></span><span style="display:flex;"><span>                y_float <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>float_op(x_float)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># 重新量化</span>
</span></span><span style="display:flex;"><span>                y_int <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>round(y_float <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>scale <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>zero_point)
</span></span><span style="display:flex;"><span>                y_int <span style="color:#f92672">=</span> y_int<span style="color:#f92672">.</span>clamp(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>)<span style="color:#f92672">.</span>to(torch<span style="color:#f92672">.</span>uint8)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">return</span> y_int
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 替换不支持的操作</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> name, module <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>named_modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(module, UnsupportedOp):
</span></span><span style="display:flex;"><span>                setattr(self<span style="color:#f92672">.</span>model, name<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;.&#39;</span>)[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>], 
</span></span><span style="display:flex;"><span>                       CustomQuantizedOp(module))
</span></span></code></pre></div><div class="edit-meta"> <br></div><nav class="pagination"><a class="nav nav-prev" href="http://localhost:1313/transformer/quantization2/" title="模型量化基础"><i class="fas fa-arrow-left" aria-hidden="true"></i>&nbsp;Prev - 模型量化基础</a>
<a class="nav nav-next" href="http://localhost:1313/transformer/do_sample_para/" title="Do_sample_para">Next - Do_sample_para <i class="fas fa-arrow-right" aria-hidden="true"></i></a>
</nav><footer> </footer>
</main>
<div class="sidebar">

<nav class="slide-menu">
<ul>
<li class=""><a href="http://localhost:1313/">about me</a></li>

<li class=" has-sub-menu"><a href="http://localhost:1313/learn_cs/">cs基础<span class="mark closed">+</span></a>
  
<ul class="sub-menu">
<li class=""><a href="http://localhost:1313/learn_cs/git-crash-course/">git-crash-course</a></li>
<li class=""><a href="http://localhost:1313/learn_cs/react-electron/ts-foundation/">ts-foundation</a></li>
<li class=""><a href="http://localhost:1313/learn_cs/react-electron/ipc/">ipc基础</a></li>
</ul>
  
</li>

<li class=" has-sub-menu"><a href="http://localhost:1313/algorithm/">算法题<span class="mark closed">+</span></a>
  
<ul class="sub-menu">
<li class=""><a href="http://localhost:1313/algorithm/stock_dp/">股票交易动态规划总结</a></li>
<li class=""><a href="http://localhost:1313/algorithm/hash_set/">哈希表相关题目</a></li>
<li class=""><a href="http://localhost:1313/algorithm/double_point/">双指针</a></li>
<li class=""><a href="http://localhost:1313/algorithm/strings/">string类题目</a></li>
<li class=""><a href="http://localhost:1313/algorithm/dynamic-programmnig/">动态规划问题</a></li>
</ul>
  
</li>

<li class=" has-sub-menu"><a href="http://localhost:1313/math_foundation/">ML中的数学<span class="mark closed">+</span></a>
  
<ul class="sub-menu">
<li class=""><a href="http://localhost:1313/math_foundation/information/">信息量</a></li>
<li class=""><a href="http://localhost:1313/math_foundation/likelihood_entropy/">似然函数_交叉熵</a></li>
<li class=""><a href="http://localhost:1313/math_foundation/kl_dpo/">Kl散度与dpo算法</a></li>
</ul>
  
</li>

<li class="parent has-sub-menu"><a href="http://localhost:1313/transformer/">ML基础<span class="mark opened">-</span></a>
  
<ul class="sub-menu">
<li class=""><a href="http://localhost:1313/transformer/quantization2/">模型量化基础</a></li>
<li class="active"><a href="http://localhost:1313/transformer/quantization/">模型量化基础代码版</a></li>
<li class=""><a href="http://localhost:1313/transformer/do_sample_para/">Do_sample_para</a></li>
<li class=""><a href="http://localhost:1313/transformer/nn_begin/">Nn Begin</a></li>
<li class=""><a href="http://localhost:1313/transformer/entropy/">Entropy</a></li>
</ul>
  
</li>

<li class=" has-sub-menu"><a href="http://localhost:1313/kubernetes/">kubernetes<span class="mark closed">+</span></a>
  
<ul class="sub-menu">
<li class=""><a href="http://localhost:1313/kubernetes/installation/">Installation</a></li>
</ul>
  
</li>

<li class=""><a href="http://localhost:1313/learn_english/">英语学习</a>
  
</li>

<li class=" has-sub-menu"><a href="http://localhost:1313/golang/">golang<span class="mark closed">+</span></a>
  
<ul class="sub-menu">
<li class=""><a href="http://localhost:1313/golang/byte-character/">字符编码基础知识详解</a></li>
<li class=""><a href="http://localhost:1313/golang/matrix-golang/">matrix-golang</a></li>
<li class=""><a href="http://localhost:1313/golang/sort/">sort包用法</a></li>
<li class=""><a href="http://localhost:1313/golang/foundation/">Go 语言基础知识</a></li>
<li class=""><a href="http://localhost:1313/golang/base/">Base</a></li>
</ul>
  
</li>

<li class=" has-sub-menu"><a href="http://localhost:1313/linux_foundation/">Linux基础<span class="mark closed">+</span></a>
  
<ul class="sub-menu">
<li class=""><a href="http://localhost:1313/linux_foundation/linux-commands/">50个常用Linux命令</a></li>
<li class=""><a href="http://localhost:1313/linux_foundation/cs_foundation/">计算机基础知识</a></li>
<li class=""><a href="http://localhost:1313/linux_foundation/linux-common/">Linux Common</a></li>
</ul>
  
</li>

<li class=" has-sub-menu"><a href="http://localhost:1313/exercise/">workout<span class="mark closed">+</span></a>
  
<ul class="sub-menu">
<li class=""><a href="http://localhost:1313/exercise/workout/">Workout</a></li>
</ul>
  
</li>

<li class=" has-sub-menu"><a href="http://localhost:1313/others/">others<span class="mark closed">+</span></a>
  
<ul class="sub-menu">
<li class=""><a href="http://localhost:1313/others/vc-news/">Vc News</a></li>
<li class=""><a href="http://localhost:1313/others/create-hugo-gitpage/">使用 Hugo 和 GitHub Pages 创建个人网站</a></li>
</ul>
  
</li>
</ul>
</nav>

 
<div class="sidebar-footer"></div>
</div>

</div><a href="#" id="backtothetop-fixed" class="backtothetop"
 data-backtothetop-duration="600"
 data-backtothetop-easing="easeOutQuart"
 data-backtothetop-fixed-fadeIn="1000"
 data-backtothetop-fixed-fadeOut="1000"
 data-backtothetop-fixed-bottom="10"
 data-backtothetop-fixed-right="20">
<span class="fa-layers fa-fw">
<i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i>
</span></a>
</div>
</body>
</html>
