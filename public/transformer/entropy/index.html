<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Entropy - 高新 | AI平台开发工程师</title>
<meta name=description content="AI平台开发工程师，专注于AI平台工程和Kubernetes云原生技术。拥有AI平台开发、GPU资源优化和AI服务部署经验"><meta name=generator content="Hugo 0.145.0"><link href=https://mlcore-engine.github.io//index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlcore-engine.github.io/transformer/entropy/><link rel=stylesheet href=https://mlcore-engine.github.io/css/theme.min.css><link rel=stylesheet href=https://mlcore-engine.github.io/css/chroma.min.css><script defer src=https://mlcore-engine.github.io//js/fontawesome6/all.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js integrity="sha256-H3cjtrm/ztDeuhCN9I4yh4iN2Ybx/y1RM7rMmAesA0k=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js integrity="sha256-4XodgW4TwIJuDtf+v6vDJ39FVxI0veC/kSCCmnFp7ck=" crossorigin=anonymous></script><script src=https://mlcore-engine.github.io/js/bundle.js></script><style>@media screen and (min-width:480px){.sidebar{flex:0 0 20%!important;max-width:20%!important}main{flex:0 0 80%!important;max-width:80%!important}}body{background-color:#f8f5e6!important;font-family:kaiti,stkaiti,楷体,楷体_gb2312,simkai,华文楷体,Kai,-apple-system,BlinkMacSystemFont,segoe ui,Roboto,sans-serif!important;font-size:20px!important;line-height:1.8!important}.container,.content-container,main{background-color:#f8f5e6!important}.sidebar{background-color:inherit;font-size:16px!important}h1,h2,h3,h4,h5,h6{font-family:kaiti,stkaiti,楷体,楷体_gb2312,simkai,华文楷体,Kai,noto serif,Georgia,serif!important;font-weight:600!important;line-height:1.5!important}h1{font-size:2.4em!important}h2{font-size:2em!important}h3{font-size:1.7em!important}h4{font-size:1.5em!important}h5{font-size:1.3em!important}h6{font-size:1.2em!important}p{font-size:20px!important;margin-bottom:1.2em!important}li{font-size:20px!important;margin-bottom:.5em!important}article,.content,.post-content,main p,main li,main td,main th,blockquote,.markdown{font-size:20px!important}pre,code{font-family:jetbrains mono,Consolas,Monaco,andale mono,ubuntu mono,monospace!important;font-size:1.1em!important}a{color:#06c!important;text-decoration:none!important}a:hover{text-decoration:underline!important}table{font-size:20px!important}</style><meta property="og:url" content="https://mlcore-engine.github.io/transformer/entropy/"><meta property="og:site_name" content="高新 | AI平台开发工程师"><meta property="og:title" content="Entropy"><meta property="og:description" content="对于Entropy的理解 $H(X) = -\sum_{i=1}^{n} p(x_i) \log_2 p(x_i)$
1. 公式的直观解释 先来看看公式里每个部分的含义：
$H(X)$：表示随机变量 $X$ 的熵，也就是不确定性的度量。 $p(x_i)$：第 $i$ 个可能结果的概率，介于 0 到 1 之间。 $\log_2 p(x_i)$：对概率取以 2 为底的对数。因为 $p(x_i)$ 是小于 1 的数，所以 $\log_2 p(x_i)$ 是负值。 负号和求和：对所有可能结果的 $p(x_i) \log_2 p(x_i)$ 求和，然后取负号，使熵变成正值。 为什么用负号？
因为 $p(x_i)$ 小于 1 时，$\log_2 p(x_i)$ 是负数，$p(x_i) \log_2 p(x_i)$ 也是负数。加一个负号后，熵 $H(X)$ 变成正数，直观地反映不确定性的大小。"><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="transformer"><meta property="article:published_time" content="2025-04-07T10:57:56+08:00"><meta property="article:modified_time" content="2025-04-17T13:10:11+08:00"><meta property="og:image" content="https://mlcore-engine.github.io/home/me.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://mlcore-engine.github.io/home/me.png"><meta name=twitter:title content="Entropy"><meta name=twitter:description content="对于Entropy的理解 $H(X) = -\sum_{i=1}^{n} p(x_i) \log_2 p(x_i)$
1. 公式的直观解释 先来看看公式里每个部分的含义：
$H(X)$：表示随机变量 $X$ 的熵，也就是不确定性的度量。 $p(x_i)$：第 $i$ 个可能结果的概率，介于 0 到 1 之间。 $\log_2 p(x_i)$：对概率取以 2 为底的对数。因为 $p(x_i)$ 是小于 1 的数，所以 $\log_2 p(x_i)$ 是负值。 负号和求和：对所有可能结果的 $p(x_i) \log_2 p(x_i)$ 求和，然后取负号，使熵变成正值。 为什么用负号？
因为 $p(x_i)$ 小于 1 时，$\log_2 p(x_i)$ 是负数，$p(x_i) \log_2 p(x_i)$ 也是负数。加一个负号后，熵 $H(X)$ 变成正数，直观地反映不确定性的大小。"><meta itemprop=name content="Entropy"><meta itemprop=description content="对于Entropy的理解 $H(X) = -\sum_{i=1}^{n} p(x_i) \log_2 p(x_i)$
1. 公式的直观解释 先来看看公式里每个部分的含义：
$H(X)$：表示随机变量 $X$ 的熵，也就是不确定性的度量。 $p(x_i)$：第 $i$ 个可能结果的概率，介于 0 到 1 之间。 $\log_2 p(x_i)$：对概率取以 2 为底的对数。因为 $p(x_i)$ 是小于 1 的数，所以 $\log_2 p(x_i)$ 是负值。 负号和求和：对所有可能结果的 $p(x_i) \log_2 p(x_i)$ 求和，然后取负号，使熵变成正值。 为什么用负号？
因为 $p(x_i)$ 小于 1 时，$\log_2 p(x_i)$ 是负数，$p(x_i) \log_2 p(x_i)$ 也是负数。加一个负号后，熵 $H(X)$ 变成正数，直观地反映不确定性的大小。"><meta itemprop=datePublished content="2025-04-07T10:57:56+08:00"><meta itemprop=dateModified content="2025-04-17T13:10:11+08:00"><meta itemprop=wordCount content="1426"><meta itemprop=image content="https://mlcore-engine.github.io/home/me.png"><link rel=apple-touch-icon sizes=180x180 href=/favicon/favicon.png><link rel=icon type=image/png sizes=32x32 href=/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon/favicon-16x16.png><link rel=manifest href=/favicon/site.webmanifest><link rel=mask-icon href=/favicon/safari-pinned-tab.svg color=#5bbad5><link rel="shortcut icon" href=/favicon.ico><meta name=msapplication-TileColor content="#da532c"><meta name=msapplication-config content="/favicon/browserconfig.xml"><meta name=theme-color content="#ffffff"><meta name=description content="对于Entropy的理解 $H(X) = -\sum_{i=1}^{n} p(x_i) \log_2 p(x_i)$
1. 公式的直观解释 先来看看公式里每个部分的含义：
$H(X)$：表示随机变量 $X$ 的熵，也就是不确定性的度量。 $p(x_i)$：第 $i$ 个可能结果的概率，介于 0 到 1 之间。 $\log_2 p(x_i)$：对概率取以 2 为底的对数。因为 $p(x_i)$ 是小于 1 的数，所以 $\log_2 p(x_i)$ 是负值。 负号和求和：对所有可能结果的 $p(x_i) \log_2 p(x_i)$ 求和，然后取负号，使熵变成正值。 为什么用负号？
因为 $p(x_i)$ 小于 1 时，$\log_2 p(x_i)$ 是负数，$p(x_i) \log_2 p(x_i)$ 也是负数。加一个负号后，熵 $H(X)$ 变成正数，直观地反映不确定性的大小。
"><meta name=keywords content="AI,机器学习,golang,kubernetes,技术博客"><meta name=author content="高新"><meta property="og:type" content="article"><meta property="og:url" content="https://mlcore-engine.github.io/transformer/entropy/"><meta property="og:title" content="Entropy | 高新 | AI平台开发工程师"><meta property="og:description" content="对于Entropy的理解 $H(X) = -\sum_{i=1}^{n} p(x_i) \log_2 p(x_i)$
1. 公式的直观解释 先来看看公式里每个部分的含义：
$H(X)$：表示随机变量 $X$ 的熵，也就是不确定性的度量。 $p(x_i)$：第 $i$ 个可能结果的概率，介于 0 到 1 之间。 $\log_2 p(x_i)$：对概率取以 2 为底的对数。因为 $p(x_i)$ 是小于 1 的数，所以 $\log_2 p(x_i)$ 是负值。 负号和求和：对所有可能结果的 $p(x_i) \log_2 p(x_i)$ 求和，然后取负号，使熵变成正值。 为什么用负号？
因为 $p(x_i)$ 小于 1 时，$\log_2 p(x_i)$ 是负数，$p(x_i) \log_2 p(x_i)$ 也是负数。加一个负号后，熵 $H(X)$ 变成正数，直观地反映不确定性的大小。
"><meta property="og:image" content="https://mlcore-engine.github.io/home/me.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:url content="https://mlcore-engine.github.io/transformer/entropy/"><meta name=twitter:title content="Entropy | 高新 | AI平台开发工程师"><meta name=twitter:description content="对于Entropy的理解 $H(X) = -\sum_{i=1}^{n} p(x_i) \log_2 p(x_i)$
1. 公式的直观解释 先来看看公式里每个部分的含义：
$H(X)$：表示随机变量 $X$ 的熵，也就是不确定性的度量。 $p(x_i)$：第 $i$ 个可能结果的概率，介于 0 到 1 之间。 $\log_2 p(x_i)$：对概率取以 2 为底的对数。因为 $p(x_i)$ 是小于 1 的数，所以 $\log_2 p(x_i)$ 是负值。 负号和求和：对所有可能结果的 $p(x_i) \log_2 p(x_i)$ 求和，然后取负号，使熵变成正值。 为什么用负号？
因为 $p(x_i)$ 小于 1 时，$\log_2 p(x_i)$ 是负数，$p(x_i) \log_2 p(x_i)$ 也是负数。加一个负号后，熵 $H(X)$ 变成正数，直观地反映不确定性的大小。
"><meta name=twitter:image content="https://mlcore-engine.github.io/home/me.png"><link rel=canonical href=https://mlcore-engine.github.io/transformer/entropy/><link rel=stylesheet href=/css/math.css><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},svg:{fontCache:"global"}}</script><script id=MathJax-script async src=/js/mathjax/tex-svg.js></script></head><body><div class=container><header><h1>高新 | AI平台开发工程师</h1><a href=https://github.com/mlcore-engine/mlcore-engine class=github><i class="fab fa-github"></i></a><p class=description>AI平台开发工程师，专注于AI平台工程和Kubernetes云原生技术。拥有AI平台开发、GPU资源优化和AI服务部署经验</p></header><div class=content-container><main><h1>Entropy</h1><h3 id=对于entropy的理解>对于Entropy的理解</h3><p>$H(X) = -\sum_{i=1}^{n} p(x_i) \log_2 p(x_i)$</p><hr><h4 id=1-公式的直观解释>1. <strong>公式的直观解释</strong></h4><p>先来看看公式里每个部分的含义：</p><ul><li><strong>$H(X)$</strong>：表示随机变量 $X$ 的熵，也就是不确定性的度量。</li><li><strong>$p(x_i)$</strong>：第 $i$ 个可能结果的概率，介于 0 到 1 之间。</li><li><strong>$\log_2 p(x_i)$</strong>：对概率取以 2 为底的对数。因为 $p(x_i)$ 是小于 1 的数，所以 $\log_2 p(x_i)$ 是负值。</li><li><strong>负号和求和</strong>：对所有可能结果的 $p(x_i) \log_2 p(x_i)$ 求和，然后取负号，使熵变成正值。</li></ul><p><strong>为什么用负号？</strong><br>因为 $p(x_i)$ 小于 1 时，$\log_2 p(x_i)$ 是负数，$p(x_i) \log_2 p(x_i)$ 也是负数。加一个负号后，熵 $H(X)$ 变成正数，直观地反映不确定性的大小。</p><p><strong>熵的单位</strong><br>由于用的是以 2 为底的对数，熵的单位是<strong>比特（bit）</strong>，表示描述随机事件所需的信息量。</p><p><strong>物理意义</strong><br>简单来说，熵 $H(X)$ 告诉你：<strong>平均需要多少比特的信息来描述随机变量 $X$ 的一个结果</strong>。如果不确定性高，熵就大；如果结果几乎确定，熵就小。</p><hr><h4 id=2-具体例子抛硬币>2. <strong>具体例子：抛硬币</strong></h4><p>为了让您更好地理解，我们用抛硬币的例子来计算熵。抛硬币有两种可能结果：正面（H）和反面（T）。我们会看两种情况：公平硬币和不公平硬币。</p><h5 id=情况-1公平硬币><strong>情况 1：公平硬币</strong></h5><p>假设硬币是公平的，正面和反面的概率相等：</p><ul><li>正面（H）的概率 $p(H) = 0.5$</li><li>反面（T）的概率 $p(T) = 0.5$</li></ul><p>现在代入公式计算熵：</p><p>$H(X) = - \left[ p(H) \log_2 p(H) + p(T) \log_2 p(T) \right]$</p><p>代入数值：</p><p>$H(X) = - \left[ 0.5 \log_2 0.5 + 0.5 \log_2 0.5 \right]$</p><p>计算每项：</p><ul><li>$\log_2 0.5 = \log_2 \left( \frac{1}{2} \right) = -1$ （因为 $2^{-1} = 0.5$）</li><li>$0.5 \times (-1) = -0.5$</li></ul><p>所以：</p><p>$H(X) = - \left[ -0.5 + (-0.5) \right] = - [-1] = 1$</p><p><strong>熵 $H(X) = 1$ 比特</strong>。</p><p><strong>解释</strong>：<br>对于公平硬币，正面和反面的概率相同，你完全无法预测抛出的结果是什么，不确定性最大。这时熵是 1 比特，意味着你需要 1 比特的信息（比如 0 表示正面，1 表示反面）来描述结果。</p><h5 id=情况-2不公平硬币><strong>情况 2：不公平硬币</strong></h5><p>现在假设硬币是不公平的，比如：</p><ul><li>正面（H）的概率 $p(H) = 0.8$</li><li>反面（T）的概率 $p(T) = 0.2$</li></ul><p>代入公式：</p><p>$H(X) = - \left[ p(H) \log_2 p(H) + p(T) \log_2 p(T) \right]$</p><p>计算每项：</p><ul><li><p>对于正面（H）：</p><ul><li>$p(H) = 0.8$</li><li>$\log_2 0.8 \approx -0.3219$ （可以用计算器算出）</li><li>$0.8 \times (-0.3219) \approx -0.2575$</li></ul></li><li><p>对于反面（T）：</p><ul><li>$p(T) = 0.2$</li><li>$\log_2 0.2 = \log_2 \left( \frac{1}{5} \right) \approx -2.3219$</li><li>$0.2 \times (-2.3219) \approx -0.4644$</li></ul></li></ul><p>求和：</p><p>$-0.2575 + (-0.4644) = -0.7219$</p><p>取负：</p><p>$H(X) = - (-0.7219) \approx 0.7219$</p><p><strong>熵 $H(X) \approx 0.7219$ 比特</strong>。</p><p><strong>解释</strong>：<br>这次硬币偏向正面（0.8 的概率），结果更容易预测，不确定性变小了。所以熵从 1 比特下降到了 0.7219 比特，说明需要的信息量减少了。</p><h5 id=极端情况完全确定的硬币><strong>极端情况：完全确定的硬币</strong></h5><p>再看一个极端情况，假设硬币总是正面：</p><ul><li>$p(H) = 1$</li><li>$p(T) = 0$</li></ul><p>代入公式：</p><p>$H(X) = - \left[ 1 \times \log_2 1 + 0 \times \log_2 0 \right]$</p><ul><li>$\log_2 1 = 0$ （因为 $2^0 = 1$）</li><li>$0 \times \log_2 0$：虽然 $\log_2 0$ 是负无穷，但在数学约定中，$0 \times \text{无穷}$ 取 0。</li></ul><p>所以：</p><p>$H(X) = - [0 + 0] = 0$</p><p><strong>熵 $H(X) = 0$ 比特</strong>。</p><p><strong>解释</strong>：<br>结果完全确定，没有任何不确定性，所以熵为 0。你不需要任何信息就能知道结果是正面。</p><hr><h4 id=3-熵的直观理解>3. <strong>熵的直观理解</strong></h4><p>通过这几个例子，我们可以总结：</p><ul><li><p><strong>熵高 = 不确定性高</strong><br>公平硬币（$p = 0.5, 0.5$）的熵是 1 比特，不确定性最大，因为两种结果完全等可能。</p></li><li><p><strong>熵低 = 不确定性低</strong><br>不公平硬币（$p = 0.8, 0.2$）的熵是 0.7219 比特，结果更可预测；完全确定的硬币（$p = 1, 0$）熵为 0，没有不确定性。</p></li></ul><p><strong>为什么用 $\log_2$？</strong><br>以 2 为底的对数是因为信息论中常用比特（bits）作为单位，1 比特能表示两种状态（0 或 1），这和抛硬币的两种结果很契合。</p><p><strong>熵的意义</strong><br>熵 $H(X)$ 可以看作是：<strong>平均需要多少比特来编码或描述随机事件的结果</strong>。比如公平硬币需要 1 比特，而不公平硬币需要不到 1 比特。</p><hr><h4 id=4-总结>4. <strong>总结</strong></h4><p>信息熵的公式 $H(X) = -\sum_{i=1}^{n} p(x_i) \log_2 p(x_i)$ 是一个数学工具，用来量化随机事件的不确定性。通过抛硬币的例子，我们看到：</p><ul><li>公平硬币（$p = 0.5, 0.5$）：熵 = 1 比特，不确定性最大。</li><li>不公平硬币（$p = 0.8, 0.2$）：熵 ≈ 0.7219 比特，不确定性减少。</li><li>完全确定的硬币（$p = 1, 0$）：熵 = 0，没有不确定性。</li></ul><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=https://mlcore-engine.github.io/transformer/do_sample_para/ title=Do_sample_para><i class="fas fa-arrow-left" aria-hidden=true></i>&nbsp;Prev - Do_sample_para</a>
<a class="nav nav-next" href=https://mlcore-engine.github.io/kubernetes/ title=kubernetes>Next - kubernetes <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlcore-engine.github.io/>about me</a></li><li><a href=https://mlcore-engine.github.io/learn_cs/>cs基础</a></li><li class=has-sub-menu><a href=https://mlcore-engine.github.io/algorithm/>算法题<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlcore-engine.github.io/algorithm/strings/>string类题目</a></li><li><a href=https://mlcore-engine.github.io/algorithm/dynamic-programmnig/>动态规划问题</a></li></ul></li><li class=has-sub-menu><a href=https://mlcore-engine.github.io/math_foundation/>ML中的数学<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlcore-engine.github.io/math_foundation/information/>信息量</a></li><li><a href=https://mlcore-engine.github.io/math_foundation/likelihood_entropy/>似然函数_交叉熵</a></li><li><a href=https://mlcore-engine.github.io/math_foundation/kl_dpo/>Kl散度与dpo算法</a></li></ul></li><li class="parent has-sub-menu"><a href=https://mlcore-engine.github.io/transformer/>ML基础<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=https://mlcore-engine.github.io/transformer/do_sample_para/>Do_sample_para</a></li><li class=active><a href=https://mlcore-engine.github.io/transformer/entropy/>Entropy</a></li></ul></li><li class=has-sub-menu><a href=https://mlcore-engine.github.io/kubernetes/>kubernetes<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlcore-engine.github.io/kubernetes/installation/>Installation</a></li></ul></li><li><a href=https://mlcore-engine.github.io/learn_english/>英语学习</a></li><li class=has-sub-menu><a href=https://mlcore-engine.github.io/golang/>golang<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlcore-engine.github.io/golang/foundation/>Go 语言基础知识</a></li></ul></li><li class=has-sub-menu><a href=https://mlcore-engine.github.io/linux_foundation/>Linux基础<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlcore-engine.github.io/linux_foundation/linux-commands/>50个常用Linux命令</a></li><li><a href=https://mlcore-engine.github.io/linux_foundation/linux-common/>Linux Common</a></li></ul></li><li class=has-sub-menu><a href=https://mlcore-engine.github.io/exercise/>workout<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlcore-engine.github.io/exercise/workout/>Workout</a></li></ul></li><li class=has-sub-menu><a href=https://mlcore-engine.github.io/others/>others<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlcore-engine.github.io/others/create-hugo-gitpage/>使用 Hugo 和 GitHub Pages 创建个人网站</a></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>