<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Transformer on 高新 | AI平台开发工程师</title>
    <link>http://localhost:1313/4transformer/</link>
    <description>Recent content in Transformer on 高新 | AI平台开发工程师</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 15 Apr 2025 14:31:46 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/4transformer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Nn Begin</title>
      <link>http://localhost:1313/4transformer/nn-begin/</link>
      <pubDate>Tue, 15 Apr 2025 14:31:46 +0800</pubDate>
      <guid>http://localhost:1313/4transformer/nn-begin/</guid>
      <description>&lt;p&gt;以下是一个关于神经网络的教程，我将通过一个简单且具体的例子，详细解释输入层、隐藏层（传输层/全连接层）、输出层和池化层等概念，并展示计算过程，帮助你彻底理解这些概念。每次回想这个例子，你都能轻松回忆起神经网络的工作原理。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Entropy</title>
      <link>http://localhost:1313/4transformer/entropy/</link>
      <pubDate>Mon, 07 Apr 2025 10:57:56 +0800</pubDate>
      <guid>http://localhost:1313/4transformer/entropy/</guid>
      <description>&lt;h3 id=&#34;对于entropy的理解&#34;&gt;对于Entropy的理解&lt;/h3&gt;&#xA;&lt;p&gt;$$H(X) = -\sum_{i=1}^{n} p(x_i) \log_2 p(x_i)$$&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h4 id=&#34;1-公式的直观解释&#34;&gt;1. &lt;strong&gt;公式的直观解释&lt;/strong&gt;&lt;/h4&gt;&#xA;&lt;p&gt;先来看看公式里每个部分的含义：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;$H(X)$&lt;/strong&gt;：表示随机变量 $X$ 的熵，也就是不确定性的度量。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;$p(x_i)$&lt;/strong&gt;：第 $i$ 个可能结果的概率，介于 0 到 1 之间。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;$\log_2 p(x_i)$&lt;/strong&gt;：对概率取以 2 为底的对数。因为 $p(x_i)$ 是小于 1 的数，所以 $\log_2 p(x_i)$ 是负值。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;负号和求和&lt;/strong&gt;：对所有可能结果的 $p(x_i) \log_2 p(x_i)$ 求和，然后取负号，使熵变成正值。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;为什么用负号？&lt;/strong&gt;&lt;br&gt;&#xA;因为 $p(x_i)$ 小于 1 时，$\log_2 p(x_i)$ 是负数，$p(x_i) \log_2 p(x_i)$ 也是负数。加一个负号后，熵 $H(X)$ 变成正数，直观地反映不确定性的大小。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
